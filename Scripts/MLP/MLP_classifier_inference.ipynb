{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450aaf57-869e-45df-84c8-c69fdd23c5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/50745734/ipykernel_2019516/3615543969.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_PATH, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and set to evaluation mode.\n",
      "Processed 10000/10000 images.\n",
      "Evaluation on test data completed.\n",
      "Confusion matrix saved as CSV to 'confusion_matrix.csv'.\n",
      "Confusion matrix saved as PNG to 'confusion_matrix.png'.\n",
      "Test evaluation statistics saved to 'test_evaluation_stats.csv'.\n",
      "Accuracy on test set: 85.26%\n",
      "Mean inference time per image: 0.001011 seconds\n",
      "Variance of inference time per image: 0.000005 seconds²\n",
      "Inference time distribution plot saved to 'inference_time_distribution.png'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "# Import the MLPClassifier class\n",
    "from MLP_model import MLPClassifier\n",
    "\n",
    "# --------------------------- Configuration --------------------------- #\n",
    "\n",
    "# Paths to the saved model and data\n",
    "MODEL_PATH = 'MLP_best_model.pth'           # Path to the best MLP model\n",
    "DATA_ROOT = '../data'                        # Root directory for KMNIST data\n",
    "CONFUSION_MATRIX_CSV = 'confusion_matrix.csv'\n",
    "CONFUSION_MATRIX_PNG = 'confusion_matrix.png'\n",
    "STATS_CSV = 'test_evaluation_stats.csv'\n",
    "\n",
    "# --------------------------- Set Device --------------------------- #\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --------------------------- Data Transformations --------------------------- #\n",
    "\n",
    "# Define the same transformations as used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1, 1]\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image to a vector\n",
    "])\n",
    "\n",
    "# --------------------------- Load Test Dataset --------------------------- #\n",
    "\n",
    "# Load the KMNIST test dataset\n",
    "test_dataset = datasets.KMNIST(root=DATA_ROOT, train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader for test dataset with batch_size=1 to measure time per image\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# --------------------------- Load the Saved MLP Model --------------------------- #\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"Model file '{MODEL_PATH}' not found. Please ensure the path is correct.\")\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Extract model configuration\n",
    "model_config = checkpoint.get('model_config', {})\n",
    "if not model_config:\n",
    "    raise KeyError(\"Model configuration 'model_config' not found in the checkpoint.\")\n",
    "\n",
    "input_size = model_config.get('input_size')\n",
    "output_size = model_config.get('output_size')\n",
    "layer_sizes = model_config.get('layer_sizes')\n",
    "activation_functions = model_config.get('activation_functions')\n",
    "dropout_rates = model_config.get('dropout_rates')\n",
    "batch_norm = model_config.get('batch_norm')\n",
    "\n",
    "if not all([input_size, output_size, layer_sizes, activation_functions, dropout_rates, batch_norm is not None]):\n",
    "    raise ValueError(\"Incomplete model configuration found in the checkpoint.\")\n",
    "\n",
    "# ------------------- Helper Function to Reconstruct Activation Functions ------------------- #\n",
    "\n",
    "def get_activation_class(act_str):\n",
    "    \"\"\"\n",
    "    Given a string representation of an activation function class, return the actual class.\n",
    "    Example: \"<class 'torch.nn.modules.activation.LeakyReLU'>\" -> nn.LeakyReLU\n",
    "    \"\"\"\n",
    "    # Remove angle brackets and extract the class path\n",
    "    act_str_clean = act_str.strip(\"<class '>'\")\n",
    "    try:\n",
    "        module_path, class_name = act_str_clean.rsplit('.', 1)\n",
    "        module = importlib.import_module(module_path)\n",
    "        act_class = getattr(module, class_name)\n",
    "        return act_class\n",
    "    except (ValueError, ImportError, AttributeError) as e:\n",
    "        raise ValueError(f\"Error reconstructing activation function from string '{act_str}': {e}\")\n",
    "\n",
    "# Reconstruct activation functions\n",
    "reconstructed_activations = []\n",
    "for act_str in activation_functions:\n",
    "    act_class = get_activation_class(act_str)\n",
    "    # If the activation class requires parameters, you can modify this as needed\n",
    "    if act_class == nn.LeakyReLU:\n",
    "        # Assuming default slope of 0.01 if not saved\n",
    "        reconstructed_activations.append(nn.LeakyReLU(negative_slope=0.01))\n",
    "    else:\n",
    "        reconstructed_activations.append(act_class())\n",
    "\n",
    "# Initialize the MLP model\n",
    "model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    layer_sizes=layer_sizes,\n",
    "    output_size=output_size,\n",
    "    activation_functions=reconstructed_activations,\n",
    "    dropout_rates=dropout_rates,\n",
    "    batch_norm=batch_norm,\n",
    "    weight_init=None  # Assuming weights are loaded from checkpoint\n",
    ").to(device)\n",
    "\n",
    "# Load the model state dictionary\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded and set to evaluation mode.\")\n",
    "\n",
    "# --------------------------- Evaluation on Test Data --------------------------- #\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "computation_times = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, labels) in enumerate(test_loader, 1):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Synchronize CUDA for accurate timing if using GPU\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        computation_time = end_time - start_time\n",
    "        computation_times.append(computation_time)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        if idx % 10000 == 0 or idx == len(test_loader):\n",
    "            print(f\"Processed {idx}/{len(test_loader)} images.\")\n",
    "\n",
    "print(\"Evaluation on test data completed.\")\n",
    "\n",
    "# --------------------------- Compute Confusion Matrix --------------------------- #\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "class_names = [str(i) for i in range(10)]  # KMNIST has 10 classes labeled 0-9\n",
    "\n",
    "# Save confusion matrix as CSV\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "cm_csv_path = CONFUSION_MATRIX_CSV\n",
    "cm_df.to_csv(cm_csv_path)\n",
    "print(f\"Confusion matrix saved as CSV to '{cm_csv_path}'.\")\n",
    "\n",
    "# Save confusion matrix as PNG\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.ylabel('True Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.title('Confusion Matrix - MLP Classifier on KMNIST Test Set')\n",
    "plt.tight_layout()\n",
    "cm_png_path = CONFUSION_MATRIX_PNG\n",
    "plt.savefig(cm_png_path)\n",
    "plt.close()\n",
    "print(f\"Confusion matrix saved as PNG to '{cm_png_path}'.\")\n",
    "\n",
    "# --------------------------- Compute Statistics --------------------------- #\n",
    "\n",
    "computation_times_np = np.array(computation_times)\n",
    "mean_time = np.mean(computation_times_np)\n",
    "variance_time = np.var(computation_times_np)\n",
    "\n",
    "# Compute accuracy\n",
    "correct = np.sum(np.array(all_preds) == np.array(all_labels))\n",
    "total = len(all_labels)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "# --------------------------- Save Evaluation Statistics --------------------------- #\n",
    "\n",
    "stats = {\n",
    "    'mean_inference_time_per_image_sec': mean_time,\n",
    "    'variance_inference_time_per_image_sec2': variance_time,\n",
    "    'accuracy_percentage': accuracy\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame([stats])\n",
    "stats_csv_path = STATS_CSV\n",
    "\n",
    "# Check if the CSV exists; if not, write headers\n",
    "write_header = not os.path.exists(stats_csv_path)\n",
    "\n",
    "stats_df.to_csv(stats_csv_path, mode='a', header=write_header, index=False)\n",
    "print(f\"Test evaluation statistics saved to '{stats_csv_path}'.\")\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "print(f\"Mean inference time per image: {mean_time:.6f} seconds\")\n",
    "print(f\"Variance of inference time per image: {variance_time:.6f} seconds²\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
