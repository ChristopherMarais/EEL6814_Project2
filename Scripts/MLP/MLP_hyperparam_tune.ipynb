{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4c8bd-8652-406a-8e27-b6320d40de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing best validation loss from CSV: 0.3055\n",
      "Skipping hyperparameter combination 1/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 2/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 3/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 4/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 5/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 6/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 7/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 8/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 9/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 10/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 11/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 12/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 13/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 14/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 15/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 16/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 17/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 18/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 19/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 20/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 21/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 22/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 23/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 24/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 25/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 26/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 27/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 28/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 29/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 30/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 31/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 32/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 33/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 34/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 35/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 36/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 37/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 38/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 39/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 40/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 41/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 42/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 43/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 44/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 45/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 46/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 47/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 48/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 49/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 50/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 51/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 52/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 53/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 54/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 55/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 56/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 57/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 58/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 59/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 60/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 61/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 62/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 63/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 64/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 65/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 66/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 67/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 68/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 69/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 70/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 71/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 72/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 73/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 74/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 75/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 76/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 77/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 78/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 79/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 80/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 81/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 82/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 83/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 84/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 85/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 86/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 87/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 88/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 89/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 90/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 91/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 92/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 93/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 94/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 95/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 96/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 97/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 98/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 99/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 100/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 101/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 102/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 103/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 104/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 105/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 106/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 107/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 108/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 109/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 110/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 111/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 112/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 113/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 114/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 115/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 116/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 117/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 118/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 119/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 120/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 121/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 122/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 123/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 124/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 125/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 126/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 127/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 128/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 129/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 130/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 131/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 132/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 133/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 134/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 135/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 136/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 137/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 138/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 139/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 140/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 141/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 142/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 143/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 144/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 145/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 146/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 147/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 148/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 149/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 150/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 151/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 152/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 153/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 154/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 155/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 156/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 157/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 158/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 159/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 160/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 161/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 162/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 163/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 164/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 165/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 166/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 167/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 168/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 169/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 170/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 171/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 172/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 173/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 174/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 175/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 176/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 177/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 178/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 179/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 180/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 181/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 182/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 183/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 184/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 185/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 186/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 187/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 188/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 189/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Testing hyperparameter combination 190/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8210, Training Accuracy: 73.94%, Validation Loss: 0.4215, Validation Accuracy: 87.16%\n",
      "Epoch [2/200], Training Loss: 0.4975, Training Accuracy: 84.64%, Validation Loss: 0.3323, Validation Accuracy: 90.01%\n",
      "Epoch [3/200], Training Loss: 0.4256, Training Accuracy: 86.88%, Validation Loss: 0.3070, Validation Accuracy: 90.69%\n",
      "Epoch [4/200], Training Loss: 0.3827, Training Accuracy: 88.31%, Validation Loss: 0.2820, Validation Accuracy: 91.52%\n",
      "Epoch [5/200], Training Loss: 0.3559, Training Accuracy: 89.01%, Validation Loss: 0.2595, Validation Accuracy: 92.15%\n",
      "Epoch [6/200], Training Loss: 0.3338, Training Accuracy: 89.78%, Validation Loss: 0.2526, Validation Accuracy: 92.04%\n",
      "Epoch [7/200], Training Loss: 0.3134, Training Accuracy: 90.25%, Validation Loss: 0.2373, Validation Accuracy: 92.64%\n",
      "Epoch [8/200], Training Loss: 0.3071, Training Accuracy: 90.47%, Validation Loss: 0.2335, Validation Accuracy: 92.90%\n",
      "Epoch [9/200], Training Loss: 0.2903, Training Accuracy: 90.82%, Validation Loss: 0.2284, Validation Accuracy: 92.85%\n",
      "Epoch [10/200], Training Loss: 0.2852, Training Accuracy: 91.15%, Validation Loss: 0.2351, Validation Accuracy: 93.10%\n",
      "Epoch [11/200], Training Loss: 0.2730, Training Accuracy: 91.41%, Validation Loss: 0.2139, Validation Accuracy: 93.62%\n",
      "Epoch [12/200], Training Loss: 0.2622, Training Accuracy: 91.84%, Validation Loss: 0.2106, Validation Accuracy: 93.75%\n",
      "Epoch [13/200], Training Loss: 0.2598, Training Accuracy: 91.85%, Validation Loss: 0.2017, Validation Accuracy: 93.92%\n",
      "Epoch [14/200], Training Loss: 0.2547, Training Accuracy: 92.10%, Validation Loss: 0.2068, Validation Accuracy: 94.00%\n",
      "Epoch [15/200], Training Loss: 0.2492, Training Accuracy: 92.14%, Validation Loss: 0.2068, Validation Accuracy: 94.04%\n",
      "Epoch [16/200], Training Loss: 0.2362, Training Accuracy: 92.53%, Validation Loss: 0.2198, Validation Accuracy: 93.57%\n",
      "Epoch [17/200], Training Loss: 0.2343, Training Accuracy: 92.62%, Validation Loss: 0.2051, Validation Accuracy: 94.02%\n",
      "Epoch [18/200], Training Loss: 0.1997, Training Accuracy: 93.74%, Validation Loss: 0.1836, Validation Accuracy: 94.56%\n",
      "Epoch [19/200], Training Loss: 0.1859, Training Accuracy: 94.32%, Validation Loss: 0.1826, Validation Accuracy: 94.57%\n",
      "Epoch [20/200], Training Loss: 0.1854, Training Accuracy: 94.15%, Validation Loss: 0.1792, Validation Accuracy: 94.59%\n",
      "Epoch [21/200], Training Loss: 0.1804, Training Accuracy: 94.32%, Validation Loss: 0.1780, Validation Accuracy: 94.85%\n",
      "Epoch [22/200], Training Loss: 0.1768, Training Accuracy: 94.44%, Validation Loss: 0.1805, Validation Accuracy: 94.73%\n",
      "Epoch [23/200], Training Loss: 0.1774, Training Accuracy: 94.48%, Validation Loss: 0.1778, Validation Accuracy: 94.73%\n",
      "Epoch [24/200], Training Loss: 0.1751, Training Accuracy: 94.36%, Validation Loss: 0.1767, Validation Accuracy: 94.88%\n",
      "Epoch [25/200], Training Loss: 0.1733, Training Accuracy: 94.53%, Validation Loss: 0.1752, Validation Accuracy: 94.86%\n",
      "Epoch [26/200], Training Loss: 0.1708, Training Accuracy: 94.53%, Validation Loss: 0.1765, Validation Accuracy: 94.91%\n",
      "Epoch [27/200], Training Loss: 0.1687, Training Accuracy: 94.61%, Validation Loss: 0.1789, Validation Accuracy: 94.91%\n",
      "Epoch [28/200], Training Loss: 0.1709, Training Accuracy: 94.54%, Validation Loss: 0.1785, Validation Accuracy: 94.83%\n",
      "Epoch [29/200], Training Loss: 0.1699, Training Accuracy: 94.54%, Validation Loss: 0.1761, Validation Accuracy: 94.78%\n",
      "Epoch [30/200], Training Loss: 0.1685, Training Accuracy: 94.69%, Validation Loss: 0.1754, Validation Accuracy: 94.92%\n",
      "Early stopping at epoch 31\n",
      "New best model saved to MLP_best_model.pth with validation loss: 0.1754\n",
      "Result - Validation Loss: 0.1754, Validation Accuracy: 94.92%\n",
      "\n",
      "Testing hyperparameter combination 191/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.9524, Training Accuracy: 69.42%, Validation Loss: 0.4633, Validation Accuracy: 86.12%\n",
      "Epoch [2/200], Training Loss: 0.5454, Training Accuracy: 83.46%, Validation Loss: 0.3536, Validation Accuracy: 89.27%\n",
      "Epoch [3/200], Training Loss: 0.4509, Training Accuracy: 86.16%, Validation Loss: 0.3181, Validation Accuracy: 89.99%\n",
      "Epoch [4/200], Training Loss: 0.4024, Training Accuracy: 87.74%, Validation Loss: 0.2829, Validation Accuracy: 91.44%\n",
      "Epoch [5/200], Training Loss: 0.3628, Training Accuracy: 88.79%, Validation Loss: 0.2640, Validation Accuracy: 92.10%\n",
      "Epoch [6/200], Training Loss: 0.3366, Training Accuracy: 89.55%, Validation Loss: 0.2456, Validation Accuracy: 92.35%\n",
      "Epoch [7/200], Training Loss: 0.3152, Training Accuracy: 90.39%, Validation Loss: 0.2338, Validation Accuracy: 92.83%\n",
      "Epoch [8/200], Training Loss: 0.3020, Training Accuracy: 90.59%, Validation Loss: 0.2313, Validation Accuracy: 92.89%\n",
      "Epoch [9/200], Training Loss: 0.2839, Training Accuracy: 91.25%, Validation Loss: 0.2243, Validation Accuracy: 93.22%\n",
      "Epoch [10/200], Training Loss: 0.2723, Training Accuracy: 91.61%, Validation Loss: 0.2245, Validation Accuracy: 93.32%\n",
      "Epoch [11/200], Training Loss: 0.2656, Training Accuracy: 91.76%, Validation Loss: 0.2149, Validation Accuracy: 93.34%\n",
      "Epoch [12/200], Training Loss: 0.2541, Training Accuracy: 92.06%, Validation Loss: 0.2082, Validation Accuracy: 93.66%\n",
      "Epoch [13/200], Training Loss: 0.2479, Training Accuracy: 92.33%, Validation Loss: 0.2018, Validation Accuracy: 93.79%\n",
      "Epoch [14/200], Training Loss: 0.2370, Training Accuracy: 92.50%, Validation Loss: 0.2042, Validation Accuracy: 93.83%\n",
      "Epoch [15/200], Training Loss: 0.2386, Training Accuracy: 92.52%, Validation Loss: 0.2098, Validation Accuracy: 93.61%\n",
      "Epoch [16/200], Training Loss: 0.2268, Training Accuracy: 93.02%, Validation Loss: 0.1967, Validation Accuracy: 94.12%\n",
      "Epoch [17/200], Training Loss: 0.2184, Training Accuracy: 93.13%, Validation Loss: 0.2057, Validation Accuracy: 93.73%\n",
      "Epoch [18/200], Training Loss: 0.2113, Training Accuracy: 93.33%, Validation Loss: 0.2053, Validation Accuracy: 93.72%\n",
      "Epoch [19/200], Training Loss: 0.2162, Training Accuracy: 93.25%, Validation Loss: 0.1956, Validation Accuracy: 93.97%\n",
      "Epoch [20/200], Training Loss: 0.2069, Training Accuracy: 93.52%, Validation Loss: 0.1925, Validation Accuracy: 94.27%\n",
      "Epoch [21/200], Training Loss: 0.2059, Training Accuracy: 93.41%, Validation Loss: 0.1986, Validation Accuracy: 94.17%\n",
      "Epoch [22/200], Training Loss: 0.2015, Training Accuracy: 93.69%, Validation Loss: 0.1916, Validation Accuracy: 94.34%\n",
      "Epoch [23/200], Training Loss: 0.1945, Training Accuracy: 93.94%, Validation Loss: 0.1938, Validation Accuracy: 94.39%\n",
      "Epoch [24/200], Training Loss: 0.1886, Training Accuracy: 94.02%, Validation Loss: 0.1982, Validation Accuracy: 94.06%\n",
      "Epoch [25/200], Training Loss: 0.1889, Training Accuracy: 94.12%, Validation Loss: 0.1984, Validation Accuracy: 94.22%\n",
      "Epoch [26/200], Training Loss: 0.1882, Training Accuracy: 94.05%, Validation Loss: 0.1915, Validation Accuracy: 94.15%\n",
      "Epoch [27/200], Training Loss: 0.1798, Training Accuracy: 94.37%, Validation Loss: 0.1954, Validation Accuracy: 94.29%\n",
      "Epoch [28/200], Training Loss: 0.1772, Training Accuracy: 94.38%, Validation Loss: 0.1962, Validation Accuracy: 94.26%\n",
      "Epoch [29/200], Training Loss: 0.1740, Training Accuracy: 94.49%, Validation Loss: 0.1926, Validation Accuracy: 94.39%\n",
      "Epoch [30/200], Training Loss: 0.1751, Training Accuracy: 94.47%, Validation Loss: 0.1897, Validation Accuracy: 94.26%\n",
      "Epoch [31/200], Training Loss: 0.1710, Training Accuracy: 94.59%, Validation Loss: 0.1980, Validation Accuracy: 94.35%\n",
      "Epoch [32/200], Training Loss: 0.1723, Training Accuracy: 94.54%, Validation Loss: 0.1946, Validation Accuracy: 94.48%\n",
      "Epoch [33/200], Training Loss: 0.1677, Training Accuracy: 94.67%, Validation Loss: 0.1927, Validation Accuracy: 94.58%\n",
      "Epoch [34/200], Training Loss: 0.1708, Training Accuracy: 94.59%, Validation Loss: 0.1876, Validation Accuracy: 94.70%\n",
      "Epoch [35/200], Training Loss: 0.1663, Training Accuracy: 94.71%, Validation Loss: 0.1918, Validation Accuracy: 94.32%\n",
      "Epoch [36/200], Training Loss: 0.1630, Training Accuracy: 94.78%, Validation Loss: 0.1930, Validation Accuracy: 94.43%\n",
      "Epoch [37/200], Training Loss: 0.1606, Training Accuracy: 94.96%, Validation Loss: 0.1891, Validation Accuracy: 94.59%\n",
      "Epoch [38/200], Training Loss: 0.1627, Training Accuracy: 94.88%, Validation Loss: 0.1889, Validation Accuracy: 94.53%\n",
      "Epoch [39/200], Training Loss: 0.1333, Training Accuracy: 95.85%, Validation Loss: 0.1774, Validation Accuracy: 94.95%\n",
      "Epoch [40/200], Training Loss: 0.1278, Training Accuracy: 96.01%, Validation Loss: 0.1774, Validation Accuracy: 94.93%\n",
      "Epoch [41/200], Training Loss: 0.1203, Training Accuracy: 96.20%, Validation Loss: 0.1764, Validation Accuracy: 95.09%\n",
      "Epoch [42/200], Training Loss: 0.1237, Training Accuracy: 96.19%, Validation Loss: 0.1772, Validation Accuracy: 95.01%\n",
      "Epoch [43/200], Training Loss: 0.1204, Training Accuracy: 96.27%, Validation Loss: 0.1769, Validation Accuracy: 94.93%\n",
      "Epoch [44/200], Training Loss: 0.1205, Training Accuracy: 96.18%, Validation Loss: 0.1763, Validation Accuracy: 95.07%\n",
      "Epoch [45/200], Training Loss: 0.1159, Training Accuracy: 96.37%, Validation Loss: 0.1774, Validation Accuracy: 95.06%\n",
      "Epoch [46/200], Training Loss: 0.1161, Training Accuracy: 96.34%, Validation Loss: 0.1774, Validation Accuracy: 94.99%\n",
      "Epoch [47/200], Training Loss: 0.1140, Training Accuracy: 96.46%, Validation Loss: 0.1792, Validation Accuracy: 95.03%\n",
      "Epoch [48/200], Training Loss: 0.1150, Training Accuracy: 96.41%, Validation Loss: 0.1774, Validation Accuracy: 95.09%\n",
      "Epoch [49/200], Training Loss: 0.1123, Training Accuracy: 96.48%, Validation Loss: 0.1773, Validation Accuracy: 95.06%\n",
      "Early stopping at epoch 50\n",
      "Result - Validation Loss: 0.1773, Validation Accuracy: 95.06%\n",
      "\n",
      "Testing hyperparameter combination 192/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8958, Training Accuracy: 71.67%, Validation Loss: 0.4360, Validation Accuracy: 86.61%\n",
      "Epoch [2/200], Training Loss: 0.5237, Training Accuracy: 83.91%, Validation Loss: 0.3580, Validation Accuracy: 89.17%\n",
      "Epoch [3/200], Training Loss: 0.4340, Training Accuracy: 86.65%, Validation Loss: 0.3185, Validation Accuracy: 90.10%\n",
      "Epoch [4/200], Training Loss: 0.3892, Training Accuracy: 87.90%, Validation Loss: 0.2800, Validation Accuracy: 91.27%\n",
      "Epoch [5/200], Training Loss: 0.3593, Training Accuracy: 88.84%, Validation Loss: 0.2658, Validation Accuracy: 91.83%\n",
      "Epoch [6/200], Training Loss: 0.3336, Training Accuracy: 89.66%, Validation Loss: 0.2531, Validation Accuracy: 92.40%\n",
      "Epoch [7/200], Training Loss: 0.3186, Training Accuracy: 90.04%, Validation Loss: 0.2383, Validation Accuracy: 92.72%\n",
      "Epoch [8/200], Training Loss: 0.3058, Training Accuracy: 90.55%, Validation Loss: 0.2314, Validation Accuracy: 93.12%\n",
      "Epoch [9/200], Training Loss: 0.2894, Training Accuracy: 90.96%, Validation Loss: 0.2332, Validation Accuracy: 92.94%\n",
      "Epoch [10/200], Training Loss: 0.2846, Training Accuracy: 91.21%, Validation Loss: 0.2236, Validation Accuracy: 93.36%\n",
      "Epoch [11/200], Training Loss: 0.2743, Training Accuracy: 91.39%, Validation Loss: 0.2240, Validation Accuracy: 93.47%\n",
      "Epoch [12/200], Training Loss: 0.2649, Training Accuracy: 91.67%, Validation Loss: 0.2175, Validation Accuracy: 93.36%\n",
      "Epoch [13/200], Training Loss: 0.2583, Training Accuracy: 91.98%, Validation Loss: 0.2143, Validation Accuracy: 93.54%\n",
      "Epoch [14/200], Training Loss: 0.2502, Training Accuracy: 92.13%, Validation Loss: 0.2138, Validation Accuracy: 93.63%\n",
      "Epoch [15/200], Training Loss: 0.2454, Training Accuracy: 92.25%, Validation Loss: 0.2089, Validation Accuracy: 93.70%\n",
      "Epoch [16/200], Training Loss: 0.2431, Training Accuracy: 92.37%, Validation Loss: 0.2110, Validation Accuracy: 93.52%\n",
      "Epoch [17/200], Training Loss: 0.2361, Training Accuracy: 92.55%, Validation Loss: 0.2182, Validation Accuracy: 93.50%\n",
      "Epoch [18/200], Training Loss: 0.2282, Training Accuracy: 92.76%, Validation Loss: 0.2166, Validation Accuracy: 93.73%\n",
      "Epoch [19/200], Training Loss: 0.2288, Training Accuracy: 92.76%, Validation Loss: 0.2016, Validation Accuracy: 94.06%\n",
      "Epoch [20/200], Training Loss: 0.2243, Training Accuracy: 92.99%, Validation Loss: 0.2031, Validation Accuracy: 93.81%\n",
      "Epoch [21/200], Training Loss: 0.2172, Training Accuracy: 93.20%, Validation Loss: 0.1986, Validation Accuracy: 94.12%\n",
      "Epoch [22/200], Training Loss: 0.2171, Training Accuracy: 93.04%, Validation Loss: 0.1982, Validation Accuracy: 94.20%\n",
      "Epoch [23/200], Training Loss: 0.2151, Training Accuracy: 93.30%, Validation Loss: 0.1971, Validation Accuracy: 94.33%\n",
      "Epoch [24/200], Training Loss: 0.2117, Training Accuracy: 93.28%, Validation Loss: 0.2002, Validation Accuracy: 94.00%\n",
      "Epoch [25/200], Training Loss: 0.2106, Training Accuracy: 93.47%, Validation Loss: 0.1964, Validation Accuracy: 94.20%\n",
      "Epoch [26/200], Training Loss: 0.2083, Training Accuracy: 93.54%, Validation Loss: 0.2051, Validation Accuracy: 93.80%\n",
      "Epoch [27/200], Training Loss: 0.1996, Training Accuracy: 93.51%, Validation Loss: 0.1999, Validation Accuracy: 94.14%\n",
      "Epoch [28/200], Training Loss: 0.1945, Training Accuracy: 93.80%, Validation Loss: 0.1958, Validation Accuracy: 94.22%\n",
      "Epoch [29/200], Training Loss: 0.1967, Training Accuracy: 93.58%, Validation Loss: 0.2056, Validation Accuracy: 94.02%\n",
      "Epoch [30/200], Training Loss: 0.2020, Training Accuracy: 93.68%, Validation Loss: 0.1992, Validation Accuracy: 94.22%\n",
      "Epoch [31/200], Training Loss: 0.1981, Training Accuracy: 93.64%, Validation Loss: 0.1986, Validation Accuracy: 94.29%\n",
      "Epoch [32/200], Training Loss: 0.1910, Training Accuracy: 94.07%, Validation Loss: 0.1908, Validation Accuracy: 94.54%\n",
      "Epoch [33/200], Training Loss: 0.1937, Training Accuracy: 93.88%, Validation Loss: 0.2032, Validation Accuracy: 94.10%\n",
      "Epoch [34/200], Training Loss: 0.1917, Training Accuracy: 93.82%, Validation Loss: 0.1934, Validation Accuracy: 94.38%\n",
      "Epoch [35/200], Training Loss: 0.1892, Training Accuracy: 93.97%, Validation Loss: 0.1925, Validation Accuracy: 94.21%\n",
      "Epoch [36/200], Training Loss: 0.1831, Training Accuracy: 94.20%, Validation Loss: 0.1930, Validation Accuracy: 94.41%\n",
      "Epoch [37/200], Training Loss: 0.1538, Training Accuracy: 95.13%, Validation Loss: 0.1852, Validation Accuracy: 94.77%\n",
      "Epoch [38/200], Training Loss: 0.1490, Training Accuracy: 95.26%, Validation Loss: 0.1845, Validation Accuracy: 94.87%\n",
      "Epoch [39/200], Training Loss: 0.1491, Training Accuracy: 95.24%, Validation Loss: 0.1826, Validation Accuracy: 94.81%\n",
      "Epoch [40/200], Training Loss: 0.1495, Training Accuracy: 95.15%, Validation Loss: 0.1829, Validation Accuracy: 94.86%\n",
      "Epoch [41/200], Training Loss: 0.1437, Training Accuracy: 95.42%, Validation Loss: 0.1806, Validation Accuracy: 94.73%\n",
      "Epoch [42/200], Training Loss: 0.1464, Training Accuracy: 95.33%, Validation Loss: 0.1823, Validation Accuracy: 94.85%\n",
      "Epoch [43/200], Training Loss: 0.1432, Training Accuracy: 95.46%, Validation Loss: 0.1803, Validation Accuracy: 94.83%\n",
      "Epoch [44/200], Training Loss: 0.1432, Training Accuracy: 95.47%, Validation Loss: 0.1799, Validation Accuracy: 94.90%\n",
      "Epoch [45/200], Training Loss: 0.1433, Training Accuracy: 95.51%, Validation Loss: 0.1802, Validation Accuracy: 94.87%\n",
      "Epoch [46/200], Training Loss: 0.1366, Training Accuracy: 95.74%, Validation Loss: 0.1783, Validation Accuracy: 94.82%\n",
      "Epoch [47/200], Training Loss: 0.1410, Training Accuracy: 95.53%, Validation Loss: 0.1798, Validation Accuracy: 95.00%\n",
      "Epoch [48/200], Training Loss: 0.1397, Training Accuracy: 95.51%, Validation Loss: 0.1781, Validation Accuracy: 94.96%\n",
      "Epoch [49/200], Training Loss: 0.1387, Training Accuracy: 95.57%, Validation Loss: 0.1788, Validation Accuracy: 94.87%\n",
      "Epoch [50/200], Training Loss: 0.1386, Training Accuracy: 95.46%, Validation Loss: 0.1783, Validation Accuracy: 94.96%\n",
      "Epoch [51/200], Training Loss: 0.1375, Training Accuracy: 95.58%, Validation Loss: 0.1785, Validation Accuracy: 94.96%\n",
      "Epoch [52/200], Training Loss: 0.1352, Training Accuracy: 95.66%, Validation Loss: 0.1795, Validation Accuracy: 94.94%\n",
      "Epoch [53/200], Training Loss: 0.1314, Training Accuracy: 95.75%, Validation Loss: 0.1782, Validation Accuracy: 94.96%\n",
      "Early stopping at epoch 54\n",
      "Result - Validation Loss: 0.1782, Validation Accuracy: 94.96%\n",
      "\n",
      "Testing hyperparameter combination 193/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.4, 0.4], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.9252, Training Accuracy: 70.74%, Validation Loss: 0.4171, Validation Accuracy: 87.89%\n",
      "Epoch [2/200], Training Loss: 0.6693, Training Accuracy: 79.22%, Validation Loss: 0.3414, Validation Accuracy: 89.92%\n",
      "Epoch [3/200], Training Loss: 0.5944, Training Accuracy: 81.73%, Validation Loss: 0.3048, Validation Accuracy: 90.95%\n",
      "Epoch [4/200], Training Loss: 0.5516, Training Accuracy: 82.81%, Validation Loss: 0.2822, Validation Accuracy: 91.73%\n",
      "Epoch [5/200], Training Loss: 0.5225, Training Accuracy: 83.89%, Validation Loss: 0.2653, Validation Accuracy: 92.30%\n",
      "Epoch [6/200], Training Loss: 0.5031, Training Accuracy: 84.53%, Validation Loss: 0.2527, Validation Accuracy: 92.48%\n",
      "Epoch [7/200], Training Loss: 0.4922, Training Accuracy: 84.74%, Validation Loss: 0.2544, Validation Accuracy: 92.58%\n",
      "Epoch [8/200], Training Loss: 0.4801, Training Accuracy: 85.29%, Validation Loss: 0.2418, Validation Accuracy: 93.11%\n",
      "Epoch [9/200], Training Loss: 0.4678, Training Accuracy: 85.59%, Validation Loss: 0.2348, Validation Accuracy: 93.09%\n",
      "Epoch [10/200], Training Loss: 0.4657, Training Accuracy: 85.75%, Validation Loss: 0.2293, Validation Accuracy: 93.31%\n",
      "Epoch [11/200], Training Loss: 0.4521, Training Accuracy: 86.06%, Validation Loss: 0.2309, Validation Accuracy: 93.51%\n",
      "Epoch [12/200], Training Loss: 0.4420, Training Accuracy: 86.45%, Validation Loss: 0.2225, Validation Accuracy: 93.49%\n",
      "Epoch [13/200], Training Loss: 0.4401, Training Accuracy: 86.54%, Validation Loss: 0.2224, Validation Accuracy: 93.61%\n",
      "Epoch [14/200], Training Loss: 0.4351, Training Accuracy: 86.75%, Validation Loss: 0.2194, Validation Accuracy: 93.55%\n",
      "Epoch [15/200], Training Loss: 0.4334, Training Accuracy: 86.45%, Validation Loss: 0.2184, Validation Accuracy: 93.58%\n",
      "Epoch [16/200], Training Loss: 0.4273, Training Accuracy: 86.72%, Validation Loss: 0.2168, Validation Accuracy: 93.49%\n",
      "Epoch [17/200], Training Loss: 0.4254, Training Accuracy: 86.85%, Validation Loss: 0.2170, Validation Accuracy: 93.42%\n",
      "Epoch [18/200], Training Loss: 0.4182, Training Accuracy: 87.13%, Validation Loss: 0.2118, Validation Accuracy: 93.82%\n",
      "Epoch [19/200], Training Loss: 0.4175, Training Accuracy: 87.11%, Validation Loss: 0.2100, Validation Accuracy: 93.75%\n",
      "Epoch [20/200], Training Loss: 0.4094, Training Accuracy: 87.28%, Validation Loss: 0.2072, Validation Accuracy: 94.06%\n",
      "Epoch [21/200], Training Loss: 0.4174, Training Accuracy: 87.18%, Validation Loss: 0.2067, Validation Accuracy: 93.89%\n",
      "Epoch [22/200], Training Loss: 0.4084, Training Accuracy: 87.34%, Validation Loss: 0.2059, Validation Accuracy: 93.93%\n",
      "Epoch [23/200], Training Loss: 0.3998, Training Accuracy: 87.76%, Validation Loss: 0.1991, Validation Accuracy: 94.08%\n",
      "Epoch [24/200], Training Loss: 0.3999, Training Accuracy: 87.86%, Validation Loss: 0.2068, Validation Accuracy: 93.99%\n",
      "Epoch [25/200], Training Loss: 0.3931, Training Accuracy: 87.81%, Validation Loss: 0.2053, Validation Accuracy: 93.98%\n",
      "Epoch [26/200], Training Loss: 0.3958, Training Accuracy: 87.75%, Validation Loss: 0.2063, Validation Accuracy: 94.02%\n",
      "Epoch [27/200], Training Loss: 0.3950, Training Accuracy: 87.92%, Validation Loss: 0.2002, Validation Accuracy: 94.25%\n",
      "Epoch [28/200], Training Loss: 0.3741, Training Accuracy: 88.47%, Validation Loss: 0.1985, Validation Accuracy: 94.13%\n",
      "Epoch [29/200], Training Loss: 0.3678, Training Accuracy: 88.53%, Validation Loss: 0.1935, Validation Accuracy: 94.31%\n",
      "Epoch [30/200], Training Loss: 0.3702, Training Accuracy: 88.43%, Validation Loss: 0.1939, Validation Accuracy: 94.39%\n",
      "Epoch [31/200], Training Loss: 0.3671, Training Accuracy: 88.67%, Validation Loss: 0.1935, Validation Accuracy: 94.40%\n",
      "Epoch [32/200], Training Loss: 0.3668, Training Accuracy: 88.73%, Validation Loss: 0.1915, Validation Accuracy: 94.37%\n",
      "Epoch [33/200], Training Loss: 0.3631, Training Accuracy: 88.78%, Validation Loss: 0.1895, Validation Accuracy: 94.37%\n",
      "Epoch [34/200], Training Loss: 0.3607, Training Accuracy: 88.77%, Validation Loss: 0.1872, Validation Accuracy: 94.52%\n",
      "Epoch [35/200], Training Loss: 0.3574, Training Accuracy: 88.85%, Validation Loss: 0.1918, Validation Accuracy: 94.32%\n",
      "Epoch [36/200], Training Loss: 0.3598, Training Accuracy: 88.98%, Validation Loss: 0.1911, Validation Accuracy: 94.35%\n",
      "Epoch [37/200], Training Loss: 0.3559, Training Accuracy: 88.92%, Validation Loss: 0.1907, Validation Accuracy: 94.51%\n",
      "Epoch [38/200], Training Loss: 0.3551, Training Accuracy: 88.97%, Validation Loss: 0.1922, Validation Accuracy: 94.27%\n",
      "Epoch [39/200], Training Loss: 0.3539, Training Accuracy: 88.99%, Validation Loss: 0.1869, Validation Accuracy: 94.51%\n",
      "Epoch [40/200], Training Loss: 0.3533, Training Accuracy: 88.96%, Validation Loss: 0.1914, Validation Accuracy: 94.31%\n",
      "Epoch [41/200], Training Loss: 0.3556, Training Accuracy: 88.93%, Validation Loss: 0.1866, Validation Accuracy: 94.53%\n",
      "Epoch [42/200], Training Loss: 0.3517, Training Accuracy: 89.13%, Validation Loss: 0.1889, Validation Accuracy: 94.52%\n",
      "Epoch [43/200], Training Loss: 0.3615, Training Accuracy: 88.87%, Validation Loss: 0.1904, Validation Accuracy: 94.38%\n",
      "Epoch [44/200], Training Loss: 0.3488, Training Accuracy: 89.21%, Validation Loss: 0.1893, Validation Accuracy: 94.44%\n",
      "Epoch [45/200], Training Loss: 0.3496, Training Accuracy: 89.19%, Validation Loss: 0.1871, Validation Accuracy: 94.48%\n",
      "Epoch [46/200], Training Loss: 0.3559, Training Accuracy: 88.87%, Validation Loss: 0.1892, Validation Accuracy: 94.29%\n",
      "Early stopping at epoch 47\n",
      "Result - Validation Loss: 0.1892, Validation Accuracy: 94.29%\n",
      "\n",
      "Testing hyperparameter combination 194/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.4, 0.4], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.9029, Training Accuracy: 71.47%, Validation Loss: 0.4352, Validation Accuracy: 87.51%\n",
      "Epoch [2/200], Training Loss: 0.6572, Training Accuracy: 79.26%, Validation Loss: 0.3670, Validation Accuracy: 89.09%\n",
      "Epoch [3/200], Training Loss: 0.5917, Training Accuracy: 81.60%, Validation Loss: 0.3258, Validation Accuracy: 89.98%\n",
      "Epoch [4/200], Training Loss: 0.5538, Training Accuracy: 82.69%, Validation Loss: 0.3053, Validation Accuracy: 91.09%\n",
      "Epoch [5/200], Training Loss: 0.5259, Training Accuracy: 83.85%, Validation Loss: 0.2881, Validation Accuracy: 91.76%\n",
      "Epoch [6/200], Training Loss: 0.5072, Training Accuracy: 84.28%, Validation Loss: 0.2747, Validation Accuracy: 92.07%\n",
      "Epoch [7/200], Training Loss: 0.4953, Training Accuracy: 84.68%, Validation Loss: 0.2790, Validation Accuracy: 91.85%\n",
      "Epoch [8/200], Training Loss: 0.4828, Training Accuracy: 84.96%, Validation Loss: 0.2641, Validation Accuracy: 92.34%\n",
      "Epoch [9/200], Training Loss: 0.4784, Training Accuracy: 85.05%, Validation Loss: 0.2579, Validation Accuracy: 92.51%\n",
      "Epoch [10/200], Training Loss: 0.4679, Training Accuracy: 85.51%, Validation Loss: 0.2536, Validation Accuracy: 92.68%\n",
      "Epoch [11/200], Training Loss: 0.4579, Training Accuracy: 85.77%, Validation Loss: 0.2585, Validation Accuracy: 92.62%\n",
      "Epoch [12/200], Training Loss: 0.4525, Training Accuracy: 85.88%, Validation Loss: 0.2484, Validation Accuracy: 92.68%\n",
      "Epoch [13/200], Training Loss: 0.4528, Training Accuracy: 86.07%, Validation Loss: 0.2486, Validation Accuracy: 93.00%\n",
      "Epoch [14/200], Training Loss: 0.4429, Training Accuracy: 86.24%, Validation Loss: 0.2456, Validation Accuracy: 92.99%\n",
      "Epoch [15/200], Training Loss: 0.4421, Training Accuracy: 86.34%, Validation Loss: 0.2453, Validation Accuracy: 93.01%\n",
      "Epoch [16/200], Training Loss: 0.4344, Training Accuracy: 86.48%, Validation Loss: 0.2422, Validation Accuracy: 93.04%\n",
      "Epoch [17/200], Training Loss: 0.4332, Training Accuracy: 86.56%, Validation Loss: 0.2492, Validation Accuracy: 92.78%\n",
      "Epoch [18/200], Training Loss: 0.4285, Training Accuracy: 86.64%, Validation Loss: 0.2357, Validation Accuracy: 93.34%\n",
      "Epoch [19/200], Training Loss: 0.4264, Training Accuracy: 86.83%, Validation Loss: 0.2361, Validation Accuracy: 93.06%\n",
      "Epoch [20/200], Training Loss: 0.4234, Training Accuracy: 86.97%, Validation Loss: 0.2302, Validation Accuracy: 93.38%\n",
      "Epoch [21/200], Training Loss: 0.4277, Training Accuracy: 86.83%, Validation Loss: 0.2352, Validation Accuracy: 93.25%\n",
      "Epoch [22/200], Training Loss: 0.4179, Training Accuracy: 87.16%, Validation Loss: 0.2283, Validation Accuracy: 93.32%\n",
      "Epoch [23/200], Training Loss: 0.4155, Training Accuracy: 87.10%, Validation Loss: 0.2261, Validation Accuracy: 93.54%\n",
      "Epoch [24/200], Training Loss: 0.4136, Training Accuracy: 87.28%, Validation Loss: 0.2335, Validation Accuracy: 93.71%\n",
      "Epoch [25/200], Training Loss: 0.4053, Training Accuracy: 87.42%, Validation Loss: 0.2337, Validation Accuracy: 93.26%\n",
      "Epoch [26/200], Training Loss: 0.4085, Training Accuracy: 87.45%, Validation Loss: 0.2290, Validation Accuracy: 93.44%\n",
      "Epoch [27/200], Training Loss: 0.4114, Training Accuracy: 87.41%, Validation Loss: 0.2237, Validation Accuracy: 93.75%\n",
      "Epoch [28/200], Training Loss: 0.4033, Training Accuracy: 87.51%, Validation Loss: 0.2303, Validation Accuracy: 93.31%\n",
      "Epoch [29/200], Training Loss: 0.4012, Training Accuracy: 87.51%, Validation Loss: 0.2261, Validation Accuracy: 93.70%\n",
      "Epoch [30/200], Training Loss: 0.4038, Training Accuracy: 87.29%, Validation Loss: 0.2278, Validation Accuracy: 93.43%\n",
      "Epoch [31/200], Training Loss: 0.4033, Training Accuracy: 87.47%, Validation Loss: 0.2231, Validation Accuracy: 93.72%\n",
      "Epoch [32/200], Training Loss: 0.3983, Training Accuracy: 87.50%, Validation Loss: 0.2219, Validation Accuracy: 93.70%\n",
      "Epoch [33/200], Training Loss: 0.3990, Training Accuracy: 87.73%, Validation Loss: 0.2232, Validation Accuracy: 93.79%\n",
      "Epoch [34/200], Training Loss: 0.3981, Training Accuracy: 87.50%, Validation Loss: 0.2174, Validation Accuracy: 93.74%\n",
      "Epoch [35/200], Training Loss: 0.3947, Training Accuracy: 87.68%, Validation Loss: 0.2271, Validation Accuracy: 93.63%\n",
      "Epoch [36/200], Training Loss: 0.3919, Training Accuracy: 87.78%, Validation Loss: 0.2249, Validation Accuracy: 93.56%\n",
      "Epoch [37/200], Training Loss: 0.3950, Training Accuracy: 87.66%, Validation Loss: 0.2242, Validation Accuracy: 93.70%\n",
      "Epoch [38/200], Training Loss: 0.3927, Training Accuracy: 87.71%, Validation Loss: 0.2268, Validation Accuracy: 93.61%\n",
      "Epoch [39/200], Training Loss: 0.3766, Training Accuracy: 88.37%, Validation Loss: 0.2179, Validation Accuracy: 93.71%\n",
      "Early stopping at epoch 40\n",
      "Result - Validation Loss: 0.2179, Validation Accuracy: 93.71%\n",
      "\n",
      "Testing hyperparameter combination 195/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.4, 0.4], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8915, Training Accuracy: 71.84%, Validation Loss: 0.4030, Validation Accuracy: 88.07%\n",
      "Epoch [2/200], Training Loss: 0.6002, Training Accuracy: 81.48%, Validation Loss: 0.3259, Validation Accuracy: 90.05%\n",
      "Epoch [3/200], Training Loss: 0.5221, Training Accuracy: 83.89%, Validation Loss: 0.2861, Validation Accuracy: 91.15%\n",
      "Epoch [4/200], Training Loss: 0.4788, Training Accuracy: 85.40%, Validation Loss: 0.2650, Validation Accuracy: 92.05%\n",
      "Epoch [5/200], Training Loss: 0.4359, Training Accuracy: 86.49%, Validation Loss: 0.2428, Validation Accuracy: 92.70%\n",
      "Epoch [6/200], Training Loss: 0.4203, Training Accuracy: 87.07%, Validation Loss: 0.2332, Validation Accuracy: 93.02%\n",
      "Epoch [7/200], Training Loss: 0.4076, Training Accuracy: 87.41%, Validation Loss: 0.2304, Validation Accuracy: 92.92%\n",
      "Epoch [8/200], Training Loss: 0.3911, Training Accuracy: 88.05%, Validation Loss: 0.2161, Validation Accuracy: 93.51%\n",
      "Epoch [9/200], Training Loss: 0.3827, Training Accuracy: 88.23%, Validation Loss: 0.2119, Validation Accuracy: 93.62%\n",
      "Epoch [10/200], Training Loss: 0.3693, Training Accuracy: 88.58%, Validation Loss: 0.2106, Validation Accuracy: 93.68%\n",
      "Epoch [11/200], Training Loss: 0.3620, Training Accuracy: 88.92%, Validation Loss: 0.2031, Validation Accuracy: 93.90%\n",
      "Epoch [12/200], Training Loss: 0.3551, Training Accuracy: 89.13%, Validation Loss: 0.2074, Validation Accuracy: 93.82%\n",
      "Epoch [13/200], Training Loss: 0.3487, Training Accuracy: 89.37%, Validation Loss: 0.2076, Validation Accuracy: 93.77%\n",
      "Epoch [14/200], Training Loss: 0.3464, Training Accuracy: 89.26%, Validation Loss: 0.2031, Validation Accuracy: 93.86%\n",
      "Epoch [15/200], Training Loss: 0.3394, Training Accuracy: 89.33%, Validation Loss: 0.1979, Validation Accuracy: 94.09%\n",
      "Epoch [16/200], Training Loss: 0.3344, Training Accuracy: 89.58%, Validation Loss: 0.1974, Validation Accuracy: 94.10%\n",
      "Epoch [17/200], Training Loss: 0.3298, Training Accuracy: 89.71%, Validation Loss: 0.1972, Validation Accuracy: 94.10%\n",
      "Epoch [18/200], Training Loss: 0.3263, Training Accuracy: 89.89%, Validation Loss: 0.1922, Validation Accuracy: 94.25%\n",
      "Epoch [19/200], Training Loss: 0.3193, Training Accuracy: 90.16%, Validation Loss: 0.1948, Validation Accuracy: 94.15%\n",
      "Epoch [20/200], Training Loss: 0.3229, Training Accuracy: 89.95%, Validation Loss: 0.1981, Validation Accuracy: 94.17%\n",
      "Epoch [21/200], Training Loss: 0.3222, Training Accuracy: 90.03%, Validation Loss: 0.1968, Validation Accuracy: 94.10%\n",
      "Epoch [22/200], Training Loss: 0.3105, Training Accuracy: 90.16%, Validation Loss: 0.1896, Validation Accuracy: 94.43%\n",
      "Epoch [23/200], Training Loss: 0.3103, Training Accuracy: 90.35%, Validation Loss: 0.1890, Validation Accuracy: 94.29%\n",
      "Epoch [24/200], Training Loss: 0.3102, Training Accuracy: 90.39%, Validation Loss: 0.1955, Validation Accuracy: 94.37%\n",
      "Epoch [25/200], Training Loss: 0.3065, Training Accuracy: 90.47%, Validation Loss: 0.1917, Validation Accuracy: 94.42%\n",
      "Epoch [26/200], Training Loss: 0.3005, Training Accuracy: 90.47%, Validation Loss: 0.1915, Validation Accuracy: 94.34%\n",
      "Epoch [27/200], Training Loss: 0.2962, Training Accuracy: 90.81%, Validation Loss: 0.1821, Validation Accuracy: 94.59%\n",
      "Epoch [28/200], Training Loss: 0.3027, Training Accuracy: 90.57%, Validation Loss: 0.1875, Validation Accuracy: 94.47%\n",
      "Epoch [29/200], Training Loss: 0.2983, Training Accuracy: 90.73%, Validation Loss: 0.1836, Validation Accuracy: 94.75%\n",
      "Epoch [30/200], Training Loss: 0.2964, Training Accuracy: 90.72%, Validation Loss: 0.1837, Validation Accuracy: 94.47%\n",
      "Epoch [31/200], Training Loss: 0.2923, Training Accuracy: 90.71%, Validation Loss: 0.1812, Validation Accuracy: 94.66%\n",
      "Epoch [32/200], Training Loss: 0.2985, Training Accuracy: 90.65%, Validation Loss: 0.1847, Validation Accuracy: 94.42%\n",
      "Epoch [33/200], Training Loss: 0.2876, Training Accuracy: 90.96%, Validation Loss: 0.1864, Validation Accuracy: 94.39%\n",
      "Epoch [34/200], Training Loss: 0.2927, Training Accuracy: 91.03%, Validation Loss: 0.1815, Validation Accuracy: 94.68%\n",
      "Epoch [35/200], Training Loss: 0.2906, Training Accuracy: 90.86%, Validation Loss: 0.1844, Validation Accuracy: 94.56%\n",
      "Epoch [36/200], Training Loss: 0.2757, Training Accuracy: 91.31%, Validation Loss: 0.1788, Validation Accuracy: 94.71%\n",
      "Epoch [37/200], Training Loss: 0.2627, Training Accuracy: 91.79%, Validation Loss: 0.1788, Validation Accuracy: 94.71%\n",
      "Epoch [38/200], Training Loss: 0.2671, Training Accuracy: 91.69%, Validation Loss: 0.1784, Validation Accuracy: 94.75%\n",
      "Epoch [39/200], Training Loss: 0.2591, Training Accuracy: 91.90%, Validation Loss: 0.1746, Validation Accuracy: 94.82%\n",
      "Epoch [1/200], Training Loss: 0.8704, Training Accuracy: 72.58%, Validation Loss: 0.4241, Validation Accuracy: 87.54%\n",
      "Epoch [2/200], Training Loss: 0.6019, Training Accuracy: 81.29%, Validation Loss: 0.3470, Validation Accuracy: 89.24%\n",
      "Epoch [3/200], Training Loss: 0.5239, Training Accuracy: 83.92%, Validation Loss: 0.2999, Validation Accuracy: 90.73%\n",
      "Epoch [4/200], Training Loss: 0.4861, Training Accuracy: 85.05%, Validation Loss: 0.2812, Validation Accuracy: 91.53%\n",
      "Epoch [5/200], Training Loss: 0.4465, Training Accuracy: 86.06%, Validation Loss: 0.2605, Validation Accuracy: 92.56%\n",
      "Epoch [6/200], Training Loss: 0.4324, Training Accuracy: 86.62%, Validation Loss: 0.2580, Validation Accuracy: 92.37%\n",
      "Epoch [7/200], Training Loss: 0.4179, Training Accuracy: 87.04%, Validation Loss: 0.2453, Validation Accuracy: 92.78%\n",
      "Epoch [8/200], Training Loss: 0.4040, Training Accuracy: 87.60%, Validation Loss: 0.2365, Validation Accuracy: 93.07%\n",
      "Epoch [9/200], Training Loss: 0.3935, Training Accuracy: 87.89%, Validation Loss: 0.2294, Validation Accuracy: 93.22%\n",
      "Epoch [10/200], Training Loss: 0.3806, Training Accuracy: 88.14%, Validation Loss: 0.2307, Validation Accuracy: 93.02%\n",
      "Epoch [11/200], Training Loss: 0.3732, Training Accuracy: 88.50%, Validation Loss: 0.2269, Validation Accuracy: 93.40%\n",
      "Epoch [12/200], Training Loss: 0.3697, Training Accuracy: 88.55%, Validation Loss: 0.2267, Validation Accuracy: 93.11%\n",
      "Epoch [13/200], Training Loss: 0.3662, Training Accuracy: 88.75%, Validation Loss: 0.2228, Validation Accuracy: 93.52%\n",
      "Epoch [14/200], Training Loss: 0.3622, Training Accuracy: 88.81%, Validation Loss: 0.2209, Validation Accuracy: 93.52%\n",
      "Epoch [15/200], Training Loss: 0.3599, Training Accuracy: 88.90%, Validation Loss: 0.2208, Validation Accuracy: 93.42%\n",
      "Epoch [16/200], Training Loss: 0.3544, Training Accuracy: 88.98%, Validation Loss: 0.2212, Validation Accuracy: 93.52%\n",
      "Epoch [17/200], Training Loss: 0.3496, Training Accuracy: 89.20%, Validation Loss: 0.2155, Validation Accuracy: 93.57%\n",
      "Epoch [18/200], Training Loss: 0.3447, Training Accuracy: 89.28%, Validation Loss: 0.2161, Validation Accuracy: 93.65%\n",
      "Epoch [19/200], Training Loss: 0.3381, Training Accuracy: 89.45%, Validation Loss: 0.2142, Validation Accuracy: 93.49%\n",
      "Epoch [20/200], Training Loss: 0.3370, Training Accuracy: 89.51%, Validation Loss: 0.2134, Validation Accuracy: 93.64%\n",
      "Epoch [21/200], Training Loss: 0.3393, Training Accuracy: 89.41%, Validation Loss: 0.2182, Validation Accuracy: 93.47%\n",
      "Epoch [22/200], Training Loss: 0.3346, Training Accuracy: 89.53%, Validation Loss: 0.2116, Validation Accuracy: 93.86%\n",
      "Epoch [23/200], Training Loss: 0.3300, Training Accuracy: 89.68%, Validation Loss: 0.2074, Validation Accuracy: 93.88%\n",
      "Epoch [24/200], Training Loss: 0.3292, Training Accuracy: 89.74%, Validation Loss: 0.2141, Validation Accuracy: 93.96%\n",
      "Epoch [25/200], Training Loss: 0.3294, Training Accuracy: 89.76%, Validation Loss: 0.2125, Validation Accuracy: 93.92%\n",
      "Epoch [26/200], Training Loss: 0.3244, Training Accuracy: 89.95%, Validation Loss: 0.2068, Validation Accuracy: 94.03%\n",
      "Epoch [27/200], Training Loss: 0.3214, Training Accuracy: 89.97%, Validation Loss: 0.2037, Validation Accuracy: 94.04%\n",
      "Epoch [28/200], Training Loss: 0.3255, Training Accuracy: 89.85%, Validation Loss: 0.2115, Validation Accuracy: 93.95%\n",
      "Epoch [29/200], Training Loss: 0.3206, Training Accuracy: 89.92%, Validation Loss: 0.2077, Validation Accuracy: 93.99%\n",
      "Epoch [30/200], Training Loss: 0.3176, Training Accuracy: 90.08%, Validation Loss: 0.2036, Validation Accuracy: 94.09%\n",
      "Epoch [31/200], Training Loss: 0.3144, Training Accuracy: 90.19%, Validation Loss: 0.2058, Validation Accuracy: 93.91%\n",
      "Epoch [32/200], Training Loss: 0.3184, Training Accuracy: 90.14%, Validation Loss: 0.2063, Validation Accuracy: 94.04%\n",
      "Early stopping at epoch 33\n",
      "Result - Validation Loss: 0.2063, Validation Accuracy: 94.04%\n",
      "\n",
      "Testing hyperparameter combination 197/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.4, 0.4], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.9126, Training Accuracy: 71.24%, Validation Loss: 0.4258, Validation Accuracy: 87.21%\n",
      "Epoch [2/200], Training Loss: 0.5869, Training Accuracy: 81.62%, Validation Loss: 0.3307, Validation Accuracy: 89.84%\n",
      "Epoch [3/200], Training Loss: 0.5002, Training Accuracy: 84.49%, Validation Loss: 0.2940, Validation Accuracy: 90.72%\n",
      "Epoch [4/200], Training Loss: 0.4436, Training Accuracy: 86.27%, Validation Loss: 0.2635, Validation Accuracy: 91.97%\n",
      "Epoch [5/200], Training Loss: 0.4089, Training Accuracy: 87.49%, Validation Loss: 0.2378, Validation Accuracy: 92.82%\n",
      "Epoch [6/200], Training Loss: 0.3826, Training Accuracy: 88.03%, Validation Loss: 0.2307, Validation Accuracy: 92.94%\n",
      "Epoch [7/200], Training Loss: 0.3733, Training Accuracy: 88.48%, Validation Loss: 0.2250, Validation Accuracy: 93.21%\n",
      "Epoch [8/200], Training Loss: 0.3519, Training Accuracy: 88.99%, Validation Loss: 0.2064, Validation Accuracy: 93.59%\n",
      "Epoch [9/200], Training Loss: 0.3385, Training Accuracy: 89.57%, Validation Loss: 0.2077, Validation Accuracy: 93.83%\n",
      "Epoch [10/200], Training Loss: 0.3273, Training Accuracy: 89.86%, Validation Loss: 0.1970, Validation Accuracy: 94.10%\n",
      "Epoch [11/200], Training Loss: 0.3191, Training Accuracy: 90.09%, Validation Loss: 0.1989, Validation Accuracy: 93.93%\n",
      "Epoch [12/200], Training Loss: 0.3065, Training Accuracy: 90.47%, Validation Loss: 0.1957, Validation Accuracy: 94.14%\n",
      "Epoch [13/200], Training Loss: 0.3014, Training Accuracy: 90.70%, Validation Loss: 0.1909, Validation Accuracy: 94.37%\n",
      "Epoch [14/200], Training Loss: 0.2981, Training Accuracy: 90.75%, Validation Loss: 0.1898, Validation Accuracy: 94.35%\n",
      "Epoch [15/200], Training Loss: 0.2879, Training Accuracy: 90.97%, Validation Loss: 0.1876, Validation Accuracy: 94.31%\n",
      "Epoch [16/200], Training Loss: 0.2881, Training Accuracy: 91.08%, Validation Loss: 0.1880, Validation Accuracy: 94.51%\n",
      "Epoch [17/200], Training Loss: 0.2724, Training Accuracy: 91.49%, Validation Loss: 0.1884, Validation Accuracy: 94.36%\n",
      "Epoch [18/200], Training Loss: 0.2836, Training Accuracy: 91.24%, Validation Loss: 0.1857, Validation Accuracy: 94.50%\n",
      "Epoch [19/200], Training Loss: 0.2740, Training Accuracy: 91.42%, Validation Loss: 0.1845, Validation Accuracy: 94.62%\n",
      "Epoch [20/200], Training Loss: 0.2665, Training Accuracy: 91.71%, Validation Loss: 0.1846, Validation Accuracy: 94.66%\n",
      "Epoch [21/200], Training Loss: 0.2638, Training Accuracy: 91.63%, Validation Loss: 0.1875, Validation Accuracy: 94.26%\n",
      "Epoch [22/200], Training Loss: 0.2591, Training Accuracy: 91.93%, Validation Loss: 0.1871, Validation Accuracy: 94.54%\n",
      "Epoch [23/200], Training Loss: 0.2620, Training Accuracy: 91.81%, Validation Loss: 0.1846, Validation Accuracy: 94.59%\n",
      "Epoch [24/200], Training Loss: 0.2415, Training Accuracy: 92.47%, Validation Loss: 0.1810, Validation Accuracy: 94.65%\n",
      "Epoch [25/200], Training Loss: 0.2372, Training Accuracy: 92.63%, Validation Loss: 0.1829, Validation Accuracy: 94.67%\n",
      "Epoch [26/200], Training Loss: 0.2297, Training Accuracy: 92.79%, Validation Loss: 0.1789, Validation Accuracy: 94.88%\n",
      "Epoch [27/200], Training Loss: 0.2260, Training Accuracy: 92.83%, Validation Loss: 0.1754, Validation Accuracy: 94.96%\n",
      "Epoch [28/200], Training Loss: 0.2267, Training Accuracy: 92.98%, Validation Loss: 0.1762, Validation Accuracy: 94.95%\n",
      "Epoch [29/200], Training Loss: 0.2236, Training Accuracy: 92.92%, Validation Loss: 0.1733, Validation Accuracy: 95.03%\n",
      "Epoch [30/200], Training Loss: 0.2213, Training Accuracy: 93.09%, Validation Loss: 0.1750, Validation Accuracy: 94.94%\n",
      "Epoch [31/200], Training Loss: 0.2257, Training Accuracy: 92.87%, Validation Loss: 0.1757, Validation Accuracy: 95.13%\n",
      "Epoch [32/200], Training Loss: 0.2254, Training Accuracy: 92.98%, Validation Loss: 0.1742, Validation Accuracy: 95.11%\n",
      "Epoch [33/200], Training Loss: 0.2232, Training Accuracy: 93.00%, Validation Loss: 0.1752, Validation Accuracy: 94.94%\n",
      "Epoch [34/200], Training Loss: 0.2178, Training Accuracy: 93.28%, Validation Loss: 0.1746, Validation Accuracy: 95.03%\n",
      "Early stopping at epoch 35\n",
      "New best model saved to MLP_best_model.pth with validation loss: 0.1746\n",
      "Result - Validation Loss: 0.1746, Validation Accuracy: 95.03%\n",
      "\n",
      "Testing hyperparameter combination 198/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.4, 0.4], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8890, Training Accuracy: 72.21%, Validation Loss: 0.4399, Validation Accuracy: 86.98%\n",
      "Epoch [2/200], Training Loss: 0.5887, Training Accuracy: 81.55%, Validation Loss: 0.3509, Validation Accuracy: 89.19%\n",
      "Epoch [3/200], Training Loss: 0.5065, Training Accuracy: 84.35%, Validation Loss: 0.3152, Validation Accuracy: 90.30%\n",
      "Epoch [4/200], Training Loss: 0.4563, Training Accuracy: 85.89%, Validation Loss: 0.2885, Validation Accuracy: 91.21%\n",
      "Epoch [5/200], Training Loss: 0.4252, Training Accuracy: 86.82%, Validation Loss: 0.2616, Validation Accuracy: 92.04%\n",
      "Epoch [6/200], Training Loss: 0.3986, Training Accuracy: 87.55%, Validation Loss: 0.2578, Validation Accuracy: 92.20%\n",
      "Epoch [7/200], Training Loss: 0.3845, Training Accuracy: 88.07%, Validation Loss: 0.2440, Validation Accuracy: 92.69%\n",
      "Epoch [8/200], Training Loss: 0.3698, Training Accuracy: 88.50%, Validation Loss: 0.2303, Validation Accuracy: 93.16%\n",
      "Epoch [9/200], Training Loss: 0.3548, Training Accuracy: 89.02%, Validation Loss: 0.2313, Validation Accuracy: 93.08%\n",
      "Epoch [10/200], Training Loss: 0.3454, Training Accuracy: 89.28%, Validation Loss: 0.2175, Validation Accuracy: 93.57%\n",
      "Epoch [11/200], Training Loss: 0.3397, Training Accuracy: 89.41%, Validation Loss: 0.2203, Validation Accuracy: 93.34%\n",
      "Epoch [12/200], Training Loss: 0.3293, Training Accuracy: 89.82%, Validation Loss: 0.2186, Validation Accuracy: 93.39%\n",
      "Epoch [13/200], Training Loss: 0.3233, Training Accuracy: 89.80%, Validation Loss: 0.2128, Validation Accuracy: 93.50%\n",
      "Epoch [14/200], Training Loss: 0.3165, Training Accuracy: 90.22%, Validation Loss: 0.2155, Validation Accuracy: 93.68%\n",
      "Epoch [15/200], Training Loss: 0.3133, Training Accuracy: 90.15%, Validation Loss: 0.2136, Validation Accuracy: 93.50%\n",
      "Epoch [16/200], Training Loss: 0.3110, Training Accuracy: 90.31%, Validation Loss: 0.2100, Validation Accuracy: 93.63%\n",
      "Epoch [17/200], Training Loss: 0.2977, Training Accuracy: 90.70%, Validation Loss: 0.2088, Validation Accuracy: 93.76%\n",
      "Epoch [18/200], Training Loss: 0.3054, Training Accuracy: 90.32%, Validation Loss: 0.2106, Validation Accuracy: 93.53%\n",
      "Epoch [19/200], Training Loss: 0.2978, Training Accuracy: 90.61%, Validation Loss: 0.2093, Validation Accuracy: 93.65%\n",
      "Epoch [20/200], Training Loss: 0.2941, Training Accuracy: 90.78%, Validation Loss: 0.2061, Validation Accuracy: 93.87%\n",
      "Epoch [21/200], Training Loss: 0.2939, Training Accuracy: 90.81%, Validation Loss: 0.2077, Validation Accuracy: 93.80%\n",
      "Epoch [22/200], Training Loss: 0.2842, Training Accuracy: 91.14%, Validation Loss: 0.2029, Validation Accuracy: 93.86%\n",
      "Epoch [23/200], Training Loss: 0.2880, Training Accuracy: 90.89%, Validation Loss: 0.2042, Validation Accuracy: 93.79%\n",
      "Epoch [24/200], Training Loss: 0.2813, Training Accuracy: 91.26%, Validation Loss: 0.2005, Validation Accuracy: 94.15%\n",
      "Epoch [25/200], Training Loss: 0.2812, Training Accuracy: 91.16%, Validation Loss: 0.2029, Validation Accuracy: 94.05%\n",
      "Epoch [26/200], Training Loss: 0.2732, Training Accuracy: 91.33%, Validation Loss: 0.2029, Validation Accuracy: 93.97%\n",
      "Epoch [27/200], Training Loss: 0.2751, Training Accuracy: 91.27%, Validation Loss: 0.2001, Validation Accuracy: 94.10%\n",
      "Epoch [28/200], Training Loss: 0.2758, Training Accuracy: 91.41%, Validation Loss: 0.2006, Validation Accuracy: 94.05%\n",
      "Epoch [29/200], Training Loss: 0.2763, Training Accuracy: 91.31%, Validation Loss: 0.2010, Validation Accuracy: 94.04%\n",
      "Epoch [30/200], Training Loss: 0.2687, Training Accuracy: 91.50%, Validation Loss: 0.1951, Validation Accuracy: 94.41%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import random\n",
    "from MLP_model import MLPClassifier  # Import the MLPClassifier class\n",
    "from itertools import product\n",
    "\n",
    "# Function to set all random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If you are using multi-GPU.\n",
    "    \n",
    "# Set the base seed\n",
    "seed=42\n",
    "set_seed(seed)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Adjust if necessary\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image\n",
    "])\n",
    "\n",
    "# Load the KMNIST dataset\n",
    "# Load the full training dataset\n",
    "full_train_dataset = datasets.KMNIST(root='../data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Define the sizes for the training and validation datasets\n",
    "val_size = 10000\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "# When using random_split, create a generator with the seed\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# Input and output sizes\n",
    "input_size = 784  # For 28x28 images\n",
    "output_size = 10  # Number of classes\n",
    "\n",
    "# Hyperparameter grid for tuning\n",
    "hyperparameter_grid = {\n",
    "    'learning_rate': [1e-3, 1e-4, 1e-5],\n",
    "    'layer_sizes': [[128, 64], [256, 128], [512, 256]],\n",
    "    'dropout_rates': [[0.1, 0.1], [0.2, 0.2], [0.3, 0.3], [0.4, 0.4], [0.5, 0.5]],\n",
    "    'batch_norm': [[True, True], [False, False]],\n",
    "    'weight_decay': [0.0, 1e-5, 1e-4, 1e-3],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'leaky_relu_negative_slope': [0.01, 0.1],  # Negative slope for LeakyReLU\n",
    "    'num_epochs': [200],  # Max number of training epochs\n",
    "    # ReduceLROnPlateau hyperparameters\n",
    "    'scheduler_mode': ['min'],  # Mode for the scheduler\n",
    "    'scheduler_factor': [0.1],  # Factor by which the learning rate will be reduced\n",
    "    'scheduler_patience': [3],  # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    'scheduler_threshold': [1e-4],  # Threshold for measuring the new optimum\n",
    "    'scheduler_cooldown': [0],  # Number of epochs to wait before resuming normal operation after lr has been reduced\n",
    "    # Early Stopping hyperparameters\n",
    "    'early_stopping_mode': ['min'],  # Mode for early stopping\n",
    "    'early_stopping_patience': [5],  # Patience for early stopping\n",
    "    'early_stopping_delta': [1e-4],  # Minimum change to qualify as improvement\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "keys, values = zip(*hyperparameter_grid.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "csv_filename = 'MLP_hyperparameter_tuning_results.csv'\n",
    "\n",
    "# Initialize an empty set to store hashes of existing results\n",
    "existing_hashes = set()\n",
    "\n",
    "# Initialize best_val_loss to infinity\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "if os.path.exists(csv_filename):\n",
    "    with open(csv_filename, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            hparams_hash = row['hparams_hash']\n",
    "            existing_hashes.add(hparams_hash)\n",
    "            try:\n",
    "                current_val_loss = float(row['val_loss'])\n",
    "                if current_val_loss < best_val_loss:\n",
    "                    best_val_loss = current_val_loss\n",
    "            except ValueError:\n",
    "                # Handle cases where val_loss might not be a valid float\n",
    "                continue\n",
    "    print(f\"Existing best validation loss from CSV: {best_val_loss:.4f}\")\n",
    "else:\n",
    "    print(\"CSV file does not exist. Starting fresh.\")\n",
    "    # If the file does not exist, we'll create it later\n",
    "\n",
    "def train_and_evaluate(hparams):\n",
    "    # Unpack hyperparameters\n",
    "    learning_rate = hparams['learning_rate']\n",
    "    layer_sizes = hparams['layer_sizes']\n",
    "    dropout_rates = hparams['dropout_rates']\n",
    "    batch_norm = hparams['batch_norm']\n",
    "    weight_decay = hparams['weight_decay']\n",
    "    batch_size = hparams['batch_size']\n",
    "    leaky_relu_negative_slope = hparams['leaky_relu_negative_slope']\n",
    "    num_epochs = hparams.get('num_epochs', 50)\n",
    "    \n",
    "    # Scheduler hyperparameters\n",
    "    scheduler_mode = hparams['scheduler_mode']\n",
    "    scheduler_factor = hparams['scheduler_factor']\n",
    "    scheduler_patience = hparams['scheduler_patience']\n",
    "    scheduler_threshold = hparams['scheduler_threshold']\n",
    "    scheduler_cooldown = hparams['scheduler_cooldown']\n",
    "    \n",
    "    # Early Stopping hyperparameters\n",
    "    early_stopping_mode = hparams['early_stopping_mode']\n",
    "    early_stopping_patience = hparams['early_stopping_patience']\n",
    "    early_stopping_delta = hparams['early_stopping_delta']\n",
    "    \n",
    "    # Define activation functions: Always LeakyReLU with specified negative slope\n",
    "    activation_functions = [nn.LeakyReLU(negative_slope=leaky_relu_negative_slope) for _ in layer_sizes]\n",
    "\n",
    "    # Initialize the model\n",
    "    model = MLPClassifier(\n",
    "        input_size=input_size,\n",
    "        layer_sizes=layer_sizes,\n",
    "        output_size=output_size,\n",
    "        activation_functions=activation_functions,\n",
    "        dropout_rates=dropout_rates,\n",
    "        batch_norm=batch_norm,\n",
    "        weight_init=init_weights\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer (always AdamW)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler: ReduceLROnPlateau\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=scheduler_mode,\n",
    "        factor=scheduler_factor,\n",
    "        patience=scheduler_patience,\n",
    "        threshold=scheduler_threshold,\n",
    "        threshold_mode='rel',\n",
    "        cooldown=scheduler_cooldown,\n",
    "    )\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Early Stopping variables\n",
    "    best_metric = None\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "\n",
    "    # Determine the comparison operator based on mode\n",
    "    if early_stopping_mode == 'min':\n",
    "        def is_improvement(current, best):\n",
    "            return current < best - early_stopping_delta\n",
    "        best_metric = float('inf')\n",
    "    elif early_stopping_mode == 'max':\n",
    "        def is_improvement(current, best):\n",
    "            return current > best + early_stopping_delta\n",
    "        best_metric = float('-inf')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported early_stopping_mode: {early_stopping_mode}\")\n",
    "\n",
    "    # Initialize variables for logging\n",
    "    initial_lr = optimizer.param_groups[0]['lr']\n",
    "    current_lr = initial_lr\n",
    "    lr_reduction_epochs = []\n",
    "    epoch_logs = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Scheduler step: ReduceLROnPlateau expects a metric to monitor\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Check if learning rate has been reduced\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr < current_lr:\n",
    "            lr_reduction_epochs.append(epoch+1)  # Epochs are 1-indexed\n",
    "            current_lr = new_lr\n",
    "\n",
    "        # Record per-epoch logs\n",
    "        epoch_logs.append({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'learning_rate': current_lr\n",
    "        })\n",
    "\n",
    "        # Early Stopping check\n",
    "        if is_improvement(val_loss, best_metric):\n",
    "            best_metric = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            early_stop = True\n",
    "\n",
    "        # Optionally, print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Prepare training log\n",
    "    training_log = {\n",
    "        'final_epoch': epoch+1,\n",
    "        'lr_reduction_epochs': lr_reduction_epochs,\n",
    "        'epoch_logs': epoch_logs\n",
    "    }\n",
    "\n",
    "    # Return final validation loss and accuracy, training log, and the model\n",
    "    return val_loss, val_accuracy, training_log, model, activation_functions, optimizer, scheduler\n",
    "\n",
    "# Main loop for hyperparameter tuning\n",
    "results = []\n",
    "\n",
    "for idx, hparams in enumerate(hyperparameter_combinations):\n",
    "    # Set the base seed\n",
    "    set_seed(42)\n",
    "    # Generate a unique id for the hyperparameters\n",
    "    hparams_str = json.dumps(hparams, sort_keys=True)\n",
    "    hparams_hash = hashlib.md5(hparams_str.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    # Check if this combination exists in existing_results\n",
    "    if hparams_hash in existing_hashes:\n",
    "        print(f\"Skipping hyperparameter combination {idx+1}/{len(hyperparameter_combinations)}: {hparams} (already tested)\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Testing hyperparameter combination {idx+1}/{len(hyperparameter_combinations)}: {hparams}\")\n",
    "        try:\n",
    "            # Call train_and_evaluate and record the computation time\n",
    "            start_time = time.time()\n",
    "            val_loss, val_accuracy, training_log, model, activation_functions, optimizer, scheduler = train_and_evaluate(hparams)\n",
    "            end_time = time.time()\n",
    "            computation_time = end_time - start_time\n",
    "\n",
    "            # Save the per-epoch logs to a file\n",
    "            log_filename = f\"misc/training_log_{hparams_hash}.json\"\n",
    "            with open(log_filename, 'w') as f:\n",
    "                json.dump(training_log, f)\n",
    "            \n",
    "            # Append the result to the CSV file\n",
    "            with open(csv_filename, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['hparams_hash'] + list(hparams.keys()) + ['val_loss', 'val_accuracy', 'computation_time', 'final_num_epochs', 'lr_reduction_epochs', 'log_filename']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                # If the file is new, write the header\n",
    "                if csvfile.tell() == 0:\n",
    "                    writer.writeheader()\n",
    "                result_row = {'hparams_hash': hparams_hash}\n",
    "                for key, value in hparams.items():\n",
    "                    # Convert value to string using json.dumps\n",
    "                    result_row[key] = json.dumps(value)\n",
    "                result_row.update({\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'computation_time': computation_time,\n",
    "                    'final_num_epochs': training_log['final_epoch'],\n",
    "                    'lr_reduction_epochs': json.dumps(training_log['lr_reduction_epochs']),\n",
    "                    'log_filename': log_filename\n",
    "                })\n",
    "                writer.writerow(result_row)\n",
    "\n",
    "            # Update the set of existing hashes\n",
    "            existing_hashes.add(hparams_hash)\n",
    "\n",
    "            # Check if current val_loss is better than the best_val_loss\n",
    "            if val_loss < best_val_loss: \n",
    "                best_val_loss = val_loss\n",
    "                # Save the model's state_dict\n",
    "                best_model_filename = 'MLP_best_model.pth'\n",
    "                # Prepare all necessary information for saving\n",
    "                save_data = {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'model_config': {\n",
    "                        'input_size': input_size,\n",
    "                        'output_size': output_size,\n",
    "                        'layer_sizes': hparams['layer_sizes'],\n",
    "                        'activation_functions': [str(type(act)) for act in activation_functions],\n",
    "                        'dropout_rates': hparams['dropout_rates'],\n",
    "                        'batch_norm': hparams['batch_norm'],\n",
    "                    },\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),  # Save optimizer state if needed for resuming training\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),  # Save scheduler state if used\n",
    "                    'hyperparameters': hparams,  # Save the hyperparameters for reference\n",
    "                    'training_log': training_log  # Include the training log if desired\n",
    "                }\n",
    "\n",
    "                # Save to file\n",
    "                torch.save(save_data, best_model_filename)\n",
    "                print(f\"New best model saved to {best_model_filename} with validation loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Append to results for final reporting\n",
    "            results.append({'hparams': hparams, 'val_loss': val_loss, 'val_accuracy': val_accuracy})\n",
    "            print(f\"Result - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with hyperparameters {hparams}: {e}\\n\")\n",
    "            continue\n",
    "\n",
    "# Find the best hyperparameters based on validation accuracy\n",
    "if results:\n",
    "    best_result = min(results, key=lambda x: x['val_loss'])  # Changed to min based on val_loss\n",
    "    print(\"Best hyperparameters based on validation loss:\")\n",
    "    print(best_result['hparams'])\n",
    "    print(f\"Validation Loss: {best_result['val_loss']:.4f}, Validation Accuracy: {best_result['val_accuracy']:.2f}%\")\n",
    "else:\n",
    "    print(\"No results to report.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
