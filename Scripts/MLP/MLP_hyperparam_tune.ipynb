{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f4c8bd-8652-406a-8e27-b6320d40de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing best validation loss from CSV: 0.3055\n",
      "Skipping hyperparameter combination 1/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 2/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 3/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 4/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 5/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 6/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 7/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 8/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 9/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 10/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 11/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 12/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 13/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 14/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 15/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 16/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 17/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 18/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 19/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 20/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 21/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 22/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 23/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 24/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 25/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 26/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 27/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 28/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 29/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 30/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 31/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 32/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 33/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 34/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 35/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 36/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 37/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 38/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 39/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 40/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 41/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 42/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 43/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 44/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 45/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 46/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 47/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 48/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 49/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 50/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 51/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 52/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 53/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 54/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 55/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 56/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 57/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 58/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 59/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 60/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 61/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 62/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 63/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 64/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.1, 0.1], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 65/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 66/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 67/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 68/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 69/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 70/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 71/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 72/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 73/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 74/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 75/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 76/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 77/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 78/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 79/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 80/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 81/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 82/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 83/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 84/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 85/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 86/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 87/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 88/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 89/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 90/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 91/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 92/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 93/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 94/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 95/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 96/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 97/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 98/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 99/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 100/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 101/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 102/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 103/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 104/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 105/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 106/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 107/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 108/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 109/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 110/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 111/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 112/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 113/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 114/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 115/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 116/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 117/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 118/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 119/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 120/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 121/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 122/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 123/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 124/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 125/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 126/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 127/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 128/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.2, 0.2], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 129/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 130/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 131/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 132/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 133/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 134/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 135/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 136/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 137/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 138/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 139/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 140/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 141/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 142/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 143/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 144/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 145/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 146/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 147/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 148/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 149/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 150/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 151/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 152/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 153/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 154/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 155/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 156/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 157/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 158/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 159/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 160/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [True, True], 'weight_decay': 0.001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 161/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 162/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 163/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 164/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 165/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 166/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 167/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 168/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 169/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 170/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 171/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 172/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 173/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 174/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 175/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 176/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 1e-05, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Skipping hyperparameter combination 177/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001} (already tested)\n",
      "Testing hyperparameter combination 178/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7342, Training Accuracy: 76.73%, Validation Loss: 0.7389, Validation Accuracy: 77.32%\n",
      "Epoch [2/200], Training Loss: 0.4833, Training Accuracy: 85.10%, Validation Loss: 0.6746, Validation Accuracy: 79.68%\n",
      "Epoch [3/200], Training Loss: 0.4219, Training Accuracy: 87.02%, Validation Loss: 0.6034, Validation Accuracy: 81.21%\n",
      "Epoch [4/200], Training Loss: 0.3898, Training Accuracy: 87.78%, Validation Loss: 0.5697, Validation Accuracy: 82.73%\n",
      "Epoch [5/200], Training Loss: 0.3641, Training Accuracy: 88.85%, Validation Loss: 0.5520, Validation Accuracy: 82.95%\n",
      "Epoch [6/200], Training Loss: 0.3446, Training Accuracy: 89.36%, Validation Loss: 0.5092, Validation Accuracy: 84.88%\n",
      "Epoch [7/200], Training Loss: 0.3279, Training Accuracy: 89.95%, Validation Loss: 0.4897, Validation Accuracy: 85.65%\n",
      "Epoch [8/200], Training Loss: 0.3223, Training Accuracy: 90.24%, Validation Loss: 0.5107, Validation Accuracy: 85.17%\n",
      "Epoch [9/200], Training Loss: 0.3114, Training Accuracy: 90.38%, Validation Loss: 0.5207, Validation Accuracy: 84.53%\n",
      "Epoch [10/200], Training Loss: 0.3049, Training Accuracy: 90.54%, Validation Loss: 0.4999, Validation Accuracy: 85.75%\n",
      "Epoch [11/200], Training Loss: 0.2962, Training Accuracy: 90.94%, Validation Loss: 0.5596, Validation Accuracy: 84.33%\n",
      "Epoch [12/200], Training Loss: 0.2383, Training Accuracy: 92.81%, Validation Loss: 0.4576, Validation Accuracy: 87.27%\n",
      "Epoch [13/200], Training Loss: 0.2184, Training Accuracy: 93.26%, Validation Loss: 0.4473, Validation Accuracy: 87.66%\n",
      "Epoch [14/200], Training Loss: 0.2147, Training Accuracy: 93.32%, Validation Loss: 0.4566, Validation Accuracy: 87.44%\n",
      "Epoch [15/200], Training Loss: 0.2087, Training Accuracy: 93.50%, Validation Loss: 0.4306, Validation Accuracy: 88.00%\n",
      "Epoch [16/200], Training Loss: 0.2089, Training Accuracy: 93.47%, Validation Loss: 0.4331, Validation Accuracy: 87.81%\n",
      "Epoch [17/200], Training Loss: 0.2011, Training Accuracy: 93.73%, Validation Loss: 0.4350, Validation Accuracy: 87.84%\n",
      "Epoch [18/200], Training Loss: 0.2002, Training Accuracy: 93.76%, Validation Loss: 0.4389, Validation Accuracy: 87.69%\n",
      "Epoch [19/200], Training Loss: 0.1978, Training Accuracy: 93.74%, Validation Loss: 0.4354, Validation Accuracy: 87.81%\n",
      "Epoch [20/200], Training Loss: 0.1958, Training Accuracy: 93.82%, Validation Loss: 0.4335, Validation Accuracy: 88.09%\n",
      "Early stopping at epoch 21\n",
      "Result - Validation Loss: 0.4335, Validation Accuracy: 88.09%\n",
      "\n",
      "Testing hyperparameter combination 179/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7757, Training Accuracy: 75.37%, Validation Loss: 0.7190, Validation Accuracy: 77.51%\n",
      "Epoch [2/200], Training Loss: 0.4846, Training Accuracy: 85.13%, Validation Loss: 0.6171, Validation Accuracy: 81.21%\n",
      "Epoch [3/200], Training Loss: 0.4129, Training Accuracy: 87.29%, Validation Loss: 0.6190, Validation Accuracy: 80.58%\n",
      "Epoch [4/200], Training Loss: 0.3756, Training Accuracy: 88.53%, Validation Loss: 0.5498, Validation Accuracy: 83.14%\n",
      "Epoch [5/200], Training Loss: 0.3485, Training Accuracy: 89.42%, Validation Loss: 0.5348, Validation Accuracy: 83.74%\n",
      "Epoch [6/200], Training Loss: 0.3265, Training Accuracy: 89.95%, Validation Loss: 0.4924, Validation Accuracy: 85.06%\n",
      "Epoch [7/200], Training Loss: 0.3174, Training Accuracy: 90.29%, Validation Loss: 0.4954, Validation Accuracy: 85.18%\n",
      "Epoch [8/200], Training Loss: 0.2993, Training Accuracy: 90.90%, Validation Loss: 0.5346, Validation Accuracy: 84.22%\n",
      "Epoch [9/200], Training Loss: 0.2859, Training Accuracy: 91.22%, Validation Loss: 0.5099, Validation Accuracy: 85.23%\n",
      "Epoch [10/200], Training Loss: 0.2778, Training Accuracy: 91.48%, Validation Loss: 0.4769, Validation Accuracy: 85.95%\n",
      "Epoch [11/200], Training Loss: 0.2679, Training Accuracy: 91.61%, Validation Loss: 0.4739, Validation Accuracy: 86.20%\n",
      "Epoch [12/200], Training Loss: 0.2620, Training Accuracy: 91.88%, Validation Loss: 0.4743, Validation Accuracy: 86.17%\n",
      "Epoch [13/200], Training Loss: 0.2575, Training Accuracy: 92.20%, Validation Loss: 0.4627, Validation Accuracy: 86.64%\n",
      "Epoch [14/200], Training Loss: 0.2451, Training Accuracy: 92.46%, Validation Loss: 0.4990, Validation Accuracy: 85.47%\n",
      "Epoch [15/200], Training Loss: 0.2425, Training Accuracy: 92.50%, Validation Loss: 0.4640, Validation Accuracy: 86.42%\n",
      "Epoch [16/200], Training Loss: 0.2345, Training Accuracy: 92.78%, Validation Loss: 0.4416, Validation Accuracy: 87.37%\n",
      "Epoch [17/200], Training Loss: 0.2305, Training Accuracy: 92.83%, Validation Loss: 0.4377, Validation Accuracy: 87.19%\n",
      "Epoch [18/200], Training Loss: 0.2266, Training Accuracy: 93.00%, Validation Loss: 0.4519, Validation Accuracy: 86.95%\n",
      "Epoch [19/200], Training Loss: 0.2318, Training Accuracy: 92.88%, Validation Loss: 0.4576, Validation Accuracy: 86.62%\n",
      "Epoch [20/200], Training Loss: 0.2185, Training Accuracy: 93.34%, Validation Loss: 0.4689, Validation Accuracy: 86.96%\n",
      "Epoch [21/200], Training Loss: 0.2183, Training Accuracy: 93.30%, Validation Loss: 0.4648, Validation Accuracy: 86.52%\n",
      "Epoch [22/200], Training Loss: 0.1746, Training Accuracy: 94.50%, Validation Loss: 0.4259, Validation Accuracy: 88.09%\n",
      "Epoch [23/200], Training Loss: 0.1639, Training Accuracy: 94.94%, Validation Loss: 0.4267, Validation Accuracy: 88.27%\n",
      "Epoch [24/200], Training Loss: 0.1594, Training Accuracy: 95.07%, Validation Loss: 0.4243, Validation Accuracy: 88.44%\n",
      "Epoch [25/200], Training Loss: 0.1602, Training Accuracy: 95.07%, Validation Loss: 0.4223, Validation Accuracy: 88.26%\n",
      "Epoch [26/200], Training Loss: 0.1561, Training Accuracy: 95.20%, Validation Loss: 0.4233, Validation Accuracy: 88.36%\n",
      "Epoch [27/200], Training Loss: 0.1543, Training Accuracy: 95.13%, Validation Loss: 0.4184, Validation Accuracy: 88.53%\n",
      "Epoch [28/200], Training Loss: 0.1527, Training Accuracy: 95.27%, Validation Loss: 0.4292, Validation Accuracy: 88.21%\n",
      "Epoch [29/200], Training Loss: 0.1516, Training Accuracy: 95.32%, Validation Loss: 0.4227, Validation Accuracy: 88.46%\n",
      "Epoch [30/200], Training Loss: 0.1485, Training Accuracy: 95.34%, Validation Loss: 0.4244, Validation Accuracy: 88.39%\n",
      "Epoch [31/200], Training Loss: 0.1447, Training Accuracy: 95.42%, Validation Loss: 0.4223, Validation Accuracy: 88.53%\n",
      "Epoch [32/200], Training Loss: 0.1441, Training Accuracy: 95.55%, Validation Loss: 0.4221, Validation Accuracy: 88.49%\n",
      "Early stopping at epoch 33\n",
      "Result - Validation Loss: 0.4221, Validation Accuracy: 88.49%\n",
      "\n",
      "Testing hyperparameter combination 180/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7436, Training Accuracy: 76.46%, Validation Loss: 0.6971, Validation Accuracy: 78.01%\n",
      "Epoch [2/200], Training Loss: 0.4695, Training Accuracy: 85.45%, Validation Loss: 0.6299, Validation Accuracy: 80.30%\n",
      "Epoch [3/200], Training Loss: 0.4094, Training Accuracy: 87.42%, Validation Loss: 0.6148, Validation Accuracy: 80.97%\n",
      "Epoch [4/200], Training Loss: 0.3737, Training Accuracy: 88.43%, Validation Loss: 0.5384, Validation Accuracy: 84.10%\n",
      "Epoch [5/200], Training Loss: 0.3464, Training Accuracy: 89.22%, Validation Loss: 0.5156, Validation Accuracy: 84.24%\n",
      "Epoch [6/200], Training Loss: 0.3298, Training Accuracy: 89.88%, Validation Loss: 0.5230, Validation Accuracy: 84.43%\n",
      "Epoch [7/200], Training Loss: 0.3151, Training Accuracy: 90.23%, Validation Loss: 0.5052, Validation Accuracy: 85.27%\n",
      "Epoch [8/200], Training Loss: 0.3064, Training Accuracy: 90.46%, Validation Loss: 0.5232, Validation Accuracy: 84.42%\n",
      "Epoch [9/200], Training Loss: 0.2956, Training Accuracy: 90.97%, Validation Loss: 0.4876, Validation Accuracy: 86.06%\n",
      "Epoch [10/200], Training Loss: 0.2868, Training Accuracy: 91.04%, Validation Loss: 0.4852, Validation Accuracy: 86.03%\n",
      "Epoch [11/200], Training Loss: 0.2790, Training Accuracy: 91.28%, Validation Loss: 0.5019, Validation Accuracy: 85.27%\n",
      "Epoch [12/200], Training Loss: 0.2727, Training Accuracy: 91.42%, Validation Loss: 0.4873, Validation Accuracy: 86.13%\n",
      "Epoch [13/200], Training Loss: 0.2690, Training Accuracy: 91.51%, Validation Loss: 0.4501, Validation Accuracy: 86.90%\n",
      "Epoch [14/200], Training Loss: 0.2613, Training Accuracy: 91.82%, Validation Loss: 0.4599, Validation Accuracy: 86.83%\n",
      "Epoch [15/200], Training Loss: 0.2595, Training Accuracy: 91.98%, Validation Loss: 0.4688, Validation Accuracy: 86.56%\n",
      "Epoch [16/200], Training Loss: 0.2549, Training Accuracy: 91.95%, Validation Loss: 0.4553, Validation Accuracy: 86.73%\n",
      "Epoch [17/200], Training Loss: 0.2496, Training Accuracy: 92.11%, Validation Loss: 0.4457, Validation Accuracy: 87.41%\n",
      "Epoch [18/200], Training Loss: 0.2458, Training Accuracy: 92.40%, Validation Loss: 0.5118, Validation Accuracy: 85.65%\n",
      "Epoch [19/200], Training Loss: 0.2475, Training Accuracy: 92.24%, Validation Loss: 0.4438, Validation Accuracy: 87.33%\n",
      "Epoch [20/200], Training Loss: 0.2426, Training Accuracy: 92.32%, Validation Loss: 0.4778, Validation Accuracy: 86.98%\n",
      "Epoch [21/200], Training Loss: 0.2340, Training Accuracy: 92.70%, Validation Loss: 0.4442, Validation Accuracy: 87.64%\n",
      "Epoch [22/200], Training Loss: 0.2324, Training Accuracy: 92.73%, Validation Loss: 0.4351, Validation Accuracy: 88.01%\n",
      "Epoch [23/200], Training Loss: 0.2332, Training Accuracy: 92.83%, Validation Loss: 0.4786, Validation Accuracy: 86.49%\n",
      "Epoch [24/200], Training Loss: 0.2303, Training Accuracy: 92.76%, Validation Loss: 0.4645, Validation Accuracy: 87.26%\n",
      "Epoch [25/200], Training Loss: 0.2278, Training Accuracy: 92.94%, Validation Loss: 0.4935, Validation Accuracy: 86.61%\n",
      "Epoch [26/200], Training Loss: 0.2261, Training Accuracy: 92.95%, Validation Loss: 0.4588, Validation Accuracy: 86.87%\n",
      "Epoch [27/200], Training Loss: 0.1830, Training Accuracy: 94.19%, Validation Loss: 0.4246, Validation Accuracy: 88.60%\n",
      "Epoch [28/200], Training Loss: 0.1741, Training Accuracy: 94.55%, Validation Loss: 0.4272, Validation Accuracy: 88.43%\n",
      "Epoch [29/200], Training Loss: 0.1716, Training Accuracy: 94.61%, Validation Loss: 0.4249, Validation Accuracy: 88.65%\n",
      "Epoch [30/200], Training Loss: 0.1662, Training Accuracy: 94.69%, Validation Loss: 0.4222, Validation Accuracy: 88.74%\n",
      "Epoch [31/200], Training Loss: 0.1656, Training Accuracy: 94.79%, Validation Loss: 0.4223, Validation Accuracy: 88.72%\n",
      "Epoch [32/200], Training Loss: 0.1622, Training Accuracy: 94.91%, Validation Loss: 0.4222, Validation Accuracy: 88.92%\n",
      "Epoch [33/200], Training Loss: 0.1576, Training Accuracy: 95.01%, Validation Loss: 0.4196, Validation Accuracy: 88.91%\n",
      "Epoch [34/200], Training Loss: 0.1590, Training Accuracy: 94.96%, Validation Loss: 0.4145, Validation Accuracy: 88.85%\n",
      "Epoch [35/200], Training Loss: 0.1606, Training Accuracy: 94.88%, Validation Loss: 0.4150, Validation Accuracy: 88.91%\n",
      "Epoch [36/200], Training Loss: 0.1575, Training Accuracy: 95.00%, Validation Loss: 0.4251, Validation Accuracy: 88.70%\n",
      "Epoch [37/200], Training Loss: 0.1572, Training Accuracy: 95.02%, Validation Loss: 0.4204, Validation Accuracy: 88.82%\n",
      "Epoch [38/200], Training Loss: 0.1563, Training Accuracy: 94.90%, Validation Loss: 0.4201, Validation Accuracy: 88.97%\n",
      "Epoch [39/200], Training Loss: 0.1517, Training Accuracy: 95.19%, Validation Loss: 0.4178, Validation Accuracy: 89.10%\n",
      "Early stopping at epoch 40\n",
      "Result - Validation Loss: 0.4178, Validation Accuracy: 89.10%\n",
      "\n",
      "Testing hyperparameter combination 181/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8149, Training Accuracy: 74.02%, Validation Loss: 0.7509, Validation Accuracy: 76.53%\n",
      "Epoch [2/200], Training Loss: 0.4838, Training Accuracy: 85.14%, Validation Loss: 0.6167, Validation Accuracy: 81.27%\n",
      "Epoch [3/200], Training Loss: 0.4046, Training Accuracy: 87.51%, Validation Loss: 0.5447, Validation Accuracy: 83.23%\n",
      "Epoch [4/200], Training Loss: 0.3610, Training Accuracy: 88.89%, Validation Loss: 0.5206, Validation Accuracy: 84.47%\n",
      "Epoch [5/200], Training Loss: 0.3331, Training Accuracy: 89.66%, Validation Loss: 0.4905, Validation Accuracy: 85.28%\n",
      "Epoch [6/200], Training Loss: 0.3117, Training Accuracy: 90.50%, Validation Loss: 0.4920, Validation Accuracy: 85.14%\n",
      "Epoch [7/200], Training Loss: 0.2941, Training Accuracy: 91.02%, Validation Loss: 0.4970, Validation Accuracy: 85.19%\n",
      "Epoch [8/200], Training Loss: 0.2804, Training Accuracy: 91.30%, Validation Loss: 0.4907, Validation Accuracy: 84.99%\n",
      "Epoch [9/200], Training Loss: 0.2676, Training Accuracy: 91.77%, Validation Loss: 0.4764, Validation Accuracy: 85.94%\n",
      "Epoch [10/200], Training Loss: 0.2615, Training Accuracy: 91.90%, Validation Loss: 0.4604, Validation Accuracy: 86.26%\n",
      "Epoch [11/200], Training Loss: 0.2497, Training Accuracy: 92.20%, Validation Loss: 0.4390, Validation Accuracy: 86.94%\n",
      "Epoch [12/200], Training Loss: 0.2440, Training Accuracy: 92.41%, Validation Loss: 0.4498, Validation Accuracy: 87.13%\n",
      "Epoch [13/200], Training Loss: 0.2416, Training Accuracy: 92.56%, Validation Loss: 0.4702, Validation Accuracy: 86.38%\n",
      "Epoch [14/200], Training Loss: 0.2294, Training Accuracy: 92.97%, Validation Loss: 0.4597, Validation Accuracy: 86.60%\n",
      "Epoch [15/200], Training Loss: 0.2276, Training Accuracy: 92.93%, Validation Loss: 0.4513, Validation Accuracy: 87.17%\n",
      "Epoch [16/200], Training Loss: 0.1912, Training Accuracy: 94.08%, Validation Loss: 0.4245, Validation Accuracy: 87.98%\n",
      "Epoch [17/200], Training Loss: 0.1809, Training Accuracy: 94.35%, Validation Loss: 0.4165, Validation Accuracy: 88.15%\n",
      "Epoch [18/200], Training Loss: 0.1788, Training Accuracy: 94.55%, Validation Loss: 0.4184, Validation Accuracy: 88.15%\n",
      "Epoch [19/200], Training Loss: 0.1711, Training Accuracy: 94.67%, Validation Loss: 0.4175, Validation Accuracy: 88.25%\n",
      "Epoch [20/200], Training Loss: 0.1678, Training Accuracy: 94.80%, Validation Loss: 0.4208, Validation Accuracy: 88.20%\n",
      "Epoch [21/200], Training Loss: 0.1670, Training Accuracy: 94.81%, Validation Loss: 0.4244, Validation Accuracy: 88.13%\n",
      "Epoch [22/200], Training Loss: 0.1635, Training Accuracy: 94.95%, Validation Loss: 0.4197, Validation Accuracy: 88.14%\n",
      "Early stopping at epoch 23\n",
      "Result - Validation Loss: 0.4197, Validation Accuracy: 88.14%\n",
      "\n",
      "Testing hyperparameter combination 182/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7760, Training Accuracy: 75.41%, Validation Loss: 0.7136, Validation Accuracy: 77.53%\n",
      "Epoch [2/200], Training Loss: 0.4786, Training Accuracy: 85.02%, Validation Loss: 0.6069, Validation Accuracy: 81.31%\n",
      "Epoch [3/200], Training Loss: 0.4105, Training Accuracy: 87.26%, Validation Loss: 0.5517, Validation Accuracy: 82.96%\n",
      "Epoch [4/200], Training Loss: 0.3668, Training Accuracy: 88.51%, Validation Loss: 0.5157, Validation Accuracy: 84.35%\n",
      "Epoch [5/200], Training Loss: 0.3421, Training Accuracy: 89.50%, Validation Loss: 0.4988, Validation Accuracy: 85.42%\n",
      "Epoch [6/200], Training Loss: 0.3279, Training Accuracy: 89.96%, Validation Loss: 0.5015, Validation Accuracy: 84.73%\n",
      "Epoch [7/200], Training Loss: 0.3097, Training Accuracy: 90.44%, Validation Loss: 0.4980, Validation Accuracy: 85.41%\n",
      "Epoch [8/200], Training Loss: 0.2994, Training Accuracy: 90.66%, Validation Loss: 0.5083, Validation Accuracy: 84.80%\n",
      "Epoch [9/200], Training Loss: 0.2836, Training Accuracy: 91.15%, Validation Loss: 0.5256, Validation Accuracy: 84.97%\n",
      "Epoch [10/200], Training Loss: 0.2797, Training Accuracy: 91.34%, Validation Loss: 0.4853, Validation Accuracy: 85.77%\n",
      "Epoch [11/200], Training Loss: 0.2730, Training Accuracy: 91.45%, Validation Loss: 0.4640, Validation Accuracy: 86.36%\n",
      "Epoch [12/200], Training Loss: 0.2634, Training Accuracy: 91.74%, Validation Loss: 0.4609, Validation Accuracy: 86.60%\n",
      "Epoch [13/200], Training Loss: 0.2598, Training Accuracy: 91.90%, Validation Loss: 0.4552, Validation Accuracy: 86.53%\n",
      "Epoch [14/200], Training Loss: 0.2534, Training Accuracy: 92.05%, Validation Loss: 0.4822, Validation Accuracy: 86.12%\n",
      "Epoch [15/200], Training Loss: 0.2475, Training Accuracy: 92.23%, Validation Loss: 0.4611, Validation Accuracy: 87.07%\n",
      "Epoch [16/200], Training Loss: 0.2445, Training Accuracy: 92.43%, Validation Loss: 0.4491, Validation Accuracy: 86.91%\n",
      "Epoch [17/200], Training Loss: 0.2373, Training Accuracy: 92.55%, Validation Loss: 0.4460, Validation Accuracy: 87.56%\n",
      "Epoch [18/200], Training Loss: 0.2365, Training Accuracy: 92.66%, Validation Loss: 0.4697, Validation Accuracy: 86.78%\n",
      "Epoch [19/200], Training Loss: 0.2303, Training Accuracy: 92.76%, Validation Loss: 0.4400, Validation Accuracy: 86.98%\n",
      "Epoch [20/200], Training Loss: 0.2294, Training Accuracy: 92.84%, Validation Loss: 0.4472, Validation Accuracy: 87.33%\n",
      "Epoch [21/200], Training Loss: 0.2266, Training Accuracy: 92.80%, Validation Loss: 0.4484, Validation Accuracy: 86.93%\n",
      "Epoch [22/200], Training Loss: 0.2213, Training Accuracy: 93.02%, Validation Loss: 0.4371, Validation Accuracy: 87.45%\n",
      "Epoch [23/200], Training Loss: 0.2203, Training Accuracy: 92.91%, Validation Loss: 0.4463, Validation Accuracy: 87.18%\n",
      "Epoch [24/200], Training Loss: 0.2191, Training Accuracy: 93.16%, Validation Loss: 0.4414, Validation Accuracy: 87.52%\n",
      "Epoch [25/200], Training Loss: 0.2158, Training Accuracy: 93.27%, Validation Loss: 0.4543, Validation Accuracy: 86.95%\n",
      "Epoch [26/200], Training Loss: 0.2155, Training Accuracy: 93.14%, Validation Loss: 0.4385, Validation Accuracy: 87.61%\n",
      "Epoch [27/200], Training Loss: 0.1842, Training Accuracy: 94.20%, Validation Loss: 0.4141, Validation Accuracy: 88.45%\n",
      "Epoch [28/200], Training Loss: 0.1712, Training Accuracy: 94.61%, Validation Loss: 0.4192, Validation Accuracy: 88.47%\n",
      "Epoch [29/200], Training Loss: 0.1704, Training Accuracy: 94.66%, Validation Loss: 0.4091, Validation Accuracy: 88.75%\n",
      "Epoch [30/200], Training Loss: 0.1655, Training Accuracy: 94.81%, Validation Loss: 0.4115, Validation Accuracy: 88.74%\n",
      "Epoch [31/200], Training Loss: 0.1661, Training Accuracy: 94.75%, Validation Loss: 0.4106, Validation Accuracy: 88.86%\n",
      "Epoch [32/200], Training Loss: 0.1641, Training Accuracy: 94.72%, Validation Loss: 0.4101, Validation Accuracy: 88.81%\n",
      "Epoch [33/200], Training Loss: 0.1620, Training Accuracy: 94.90%, Validation Loss: 0.4106, Validation Accuracy: 88.64%\n",
      "Epoch [34/200], Training Loss: 0.1565, Training Accuracy: 95.03%, Validation Loss: 0.4090, Validation Accuracy: 88.83%\n",
      "Early stopping at epoch 35\n",
      "Result - Validation Loss: 0.4090, Validation Accuracy: 88.83%\n",
      "\n",
      "Testing hyperparameter combination 183/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8917, Training Accuracy: 71.48%, Validation Loss: 0.7770, Validation Accuracy: 75.48%\n",
      "Epoch [2/200], Training Loss: 0.5270, Training Accuracy: 83.89%, Validation Loss: 0.6592, Validation Accuracy: 79.51%\n",
      "Epoch [3/200], Training Loss: 0.4361, Training Accuracy: 86.74%, Validation Loss: 0.6178, Validation Accuracy: 80.32%\n",
      "Epoch [4/200], Training Loss: 0.3871, Training Accuracy: 88.03%, Validation Loss: 0.5768, Validation Accuracy: 81.93%\n",
      "Epoch [5/200], Training Loss: 0.3558, Training Accuracy: 89.02%, Validation Loss: 0.5267, Validation Accuracy: 83.70%\n",
      "Epoch [6/200], Training Loss: 0.3287, Training Accuracy: 89.80%, Validation Loss: 0.5064, Validation Accuracy: 84.27%\n",
      "Epoch [7/200], Training Loss: 0.3110, Training Accuracy: 90.43%, Validation Loss: 0.5064, Validation Accuracy: 84.91%\n",
      "Epoch [8/200], Training Loss: 0.2935, Training Accuracy: 90.95%, Validation Loss: 0.4964, Validation Accuracy: 85.34%\n",
      "Epoch [9/200], Training Loss: 0.2796, Training Accuracy: 91.32%, Validation Loss: 0.4879, Validation Accuracy: 85.38%\n",
      "Epoch [10/200], Training Loss: 0.2729, Training Accuracy: 91.53%, Validation Loss: 0.4710, Validation Accuracy: 86.11%\n",
      "Epoch [11/200], Training Loss: 0.2611, Training Accuracy: 91.94%, Validation Loss: 0.4742, Validation Accuracy: 86.31%\n",
      "Epoch [12/200], Training Loss: 0.2596, Training Accuracy: 92.02%, Validation Loss: 0.4712, Validation Accuracy: 86.12%\n",
      "Epoch [13/200], Training Loss: 0.2393, Training Accuracy: 92.53%, Validation Loss: 0.4634, Validation Accuracy: 86.43%\n",
      "Epoch [14/200], Training Loss: 0.2399, Training Accuracy: 92.47%, Validation Loss: 0.4667, Validation Accuracy: 86.29%\n",
      "Epoch [15/200], Training Loss: 0.2341, Training Accuracy: 92.69%, Validation Loss: 0.4616, Validation Accuracy: 86.62%\n",
      "Epoch [16/200], Training Loss: 0.2272, Training Accuracy: 92.82%, Validation Loss: 0.4482, Validation Accuracy: 86.90%\n",
      "Epoch [17/200], Training Loss: 0.2239, Training Accuracy: 93.11%, Validation Loss: 0.4463, Validation Accuracy: 86.97%\n",
      "Epoch [18/200], Training Loss: 0.2192, Training Accuracy: 93.19%, Validation Loss: 0.4482, Validation Accuracy: 87.21%\n",
      "Epoch [19/200], Training Loss: 0.2091, Training Accuracy: 93.41%, Validation Loss: 0.4407, Validation Accuracy: 87.35%\n",
      "Epoch [20/200], Training Loss: 0.2050, Training Accuracy: 93.72%, Validation Loss: 0.4410, Validation Accuracy: 87.26%\n",
      "Epoch [21/200], Training Loss: 0.2053, Training Accuracy: 93.61%, Validation Loss: 0.4378, Validation Accuracy: 87.86%\n",
      "Epoch [22/200], Training Loss: 0.2017, Training Accuracy: 93.71%, Validation Loss: 0.4468, Validation Accuracy: 87.46%\n",
      "Epoch [23/200], Training Loss: 0.1957, Training Accuracy: 93.87%, Validation Loss: 0.4403, Validation Accuracy: 87.41%\n",
      "Epoch [24/200], Training Loss: 0.1950, Training Accuracy: 93.89%, Validation Loss: 0.4428, Validation Accuracy: 87.71%\n",
      "Epoch [25/200], Training Loss: 0.1974, Training Accuracy: 93.85%, Validation Loss: 0.4334, Validation Accuracy: 88.09%\n",
      "Epoch [26/200], Training Loss: 0.1909, Training Accuracy: 93.99%, Validation Loss: 0.4601, Validation Accuracy: 87.11%\n",
      "Epoch [27/200], Training Loss: 0.1878, Training Accuracy: 94.14%, Validation Loss: 0.4269, Validation Accuracy: 88.22%\n",
      "Epoch [28/200], Training Loss: 0.1795, Training Accuracy: 94.24%, Validation Loss: 0.4305, Validation Accuracy: 88.16%\n",
      "Epoch [29/200], Training Loss: 0.1828, Training Accuracy: 94.31%, Validation Loss: 0.4464, Validation Accuracy: 87.84%\n",
      "Epoch [30/200], Training Loss: 0.1776, Training Accuracy: 94.35%, Validation Loss: 0.4515, Validation Accuracy: 87.73%\n",
      "Epoch [31/200], Training Loss: 0.1756, Training Accuracy: 94.47%, Validation Loss: 0.4558, Validation Accuracy: 87.50%\n",
      "Epoch [32/200], Training Loss: 0.1505, Training Accuracy: 95.28%, Validation Loss: 0.4186, Validation Accuracy: 88.84%\n",
      "Epoch [33/200], Training Loss: 0.1440, Training Accuracy: 95.45%, Validation Loss: 0.4220, Validation Accuracy: 88.71%\n",
      "Epoch [34/200], Training Loss: 0.1397, Training Accuracy: 95.57%, Validation Loss: 0.4158, Validation Accuracy: 88.89%\n",
      "Epoch [35/200], Training Loss: 0.1382, Training Accuracy: 95.68%, Validation Loss: 0.4189, Validation Accuracy: 89.10%\n",
      "Epoch [36/200], Training Loss: 0.1347, Training Accuracy: 95.79%, Validation Loss: 0.4177, Validation Accuracy: 88.93%\n",
      "Epoch [37/200], Training Loss: 0.1318, Training Accuracy: 95.85%, Validation Loss: 0.4196, Validation Accuracy: 88.97%\n",
      "Epoch [38/200], Training Loss: 0.1350, Training Accuracy: 95.74%, Validation Loss: 0.4188, Validation Accuracy: 89.05%\n",
      "Epoch [39/200], Training Loss: 0.1296, Training Accuracy: 96.02%, Validation Loss: 0.4175, Validation Accuracy: 89.09%\n",
      "Early stopping at epoch 40\n",
      "Result - Validation Loss: 0.4175, Validation Accuracy: 89.09%\n",
      "\n",
      "Testing hyperparameter combination 184/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.0001, 'batch_size': 128, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8410, Training Accuracy: 73.42%, Validation Loss: 0.7728, Validation Accuracy: 75.76%\n",
      "Epoch [2/200], Training Loss: 0.5003, Training Accuracy: 84.56%, Validation Loss: 0.6401, Validation Accuracy: 80.24%\n",
      "Epoch [3/200], Training Loss: 0.4214, Training Accuracy: 87.11%, Validation Loss: 0.6190, Validation Accuracy: 80.46%\n",
      "Epoch [4/200], Training Loss: 0.3784, Training Accuracy: 88.28%, Validation Loss: 0.5463, Validation Accuracy: 83.17%\n",
      "Epoch [5/200], Training Loss: 0.3523, Training Accuracy: 88.97%, Validation Loss: 0.5064, Validation Accuracy: 84.49%\n",
      "Epoch [6/200], Training Loss: 0.3274, Training Accuracy: 89.86%, Validation Loss: 0.4934, Validation Accuracy: 84.97%\n",
      "Epoch [7/200], Training Loss: 0.3120, Training Accuracy: 90.31%, Validation Loss: 0.5050, Validation Accuracy: 84.64%\n",
      "Epoch [8/200], Training Loss: 0.3008, Training Accuracy: 90.82%, Validation Loss: 0.5251, Validation Accuracy: 83.81%\n",
      "Epoch [9/200], Training Loss: 0.2888, Training Accuracy: 91.09%, Validation Loss: 0.4727, Validation Accuracy: 85.74%\n",
      "Epoch [10/200], Training Loss: 0.2813, Training Accuracy: 91.26%, Validation Loss: 0.4528, Validation Accuracy: 86.63%\n",
      "Epoch [11/200], Training Loss: 0.2675, Training Accuracy: 91.74%, Validation Loss: 0.4905, Validation Accuracy: 85.92%\n",
      "Epoch [12/200], Training Loss: 0.2663, Training Accuracy: 91.60%, Validation Loss: 0.4566, Validation Accuracy: 86.77%\n",
      "Epoch [13/200], Training Loss: 0.2575, Training Accuracy: 92.06%, Validation Loss: 0.4509, Validation Accuracy: 86.88%\n",
      "Epoch [14/200], Training Loss: 0.2538, Training Accuracy: 92.03%, Validation Loss: 0.4428, Validation Accuracy: 86.97%\n",
      "Epoch [15/200], Training Loss: 0.2465, Training Accuracy: 92.27%, Validation Loss: 0.4443, Validation Accuracy: 87.01%\n",
      "Epoch [16/200], Training Loss: 0.2425, Training Accuracy: 92.37%, Validation Loss: 0.4340, Validation Accuracy: 87.20%\n",
      "Epoch [17/200], Training Loss: 0.2370, Training Accuracy: 92.55%, Validation Loss: 0.4346, Validation Accuracy: 87.55%\n",
      "Epoch [18/200], Training Loss: 0.2346, Training Accuracy: 92.60%, Validation Loss: 0.4457, Validation Accuracy: 87.00%\n",
      "Epoch [19/200], Training Loss: 0.2321, Training Accuracy: 92.73%, Validation Loss: 0.4223, Validation Accuracy: 87.93%\n",
      "Epoch [20/200], Training Loss: 0.2252, Training Accuracy: 92.87%, Validation Loss: 0.4221, Validation Accuracy: 87.82%\n",
      "Epoch [21/200], Training Loss: 0.2194, Training Accuracy: 93.07%, Validation Loss: 0.4328, Validation Accuracy: 87.96%\n",
      "Epoch [22/200], Training Loss: 0.2216, Training Accuracy: 93.06%, Validation Loss: 0.4368, Validation Accuracy: 87.61%\n",
      "Epoch [23/200], Training Loss: 0.2178, Training Accuracy: 93.13%, Validation Loss: 0.4370, Validation Accuracy: 87.70%\n",
      "Epoch [24/200], Training Loss: 0.2113, Training Accuracy: 93.35%, Validation Loss: 0.4631, Validation Accuracy: 86.97%\n",
      "Epoch [25/200], Training Loss: 0.1824, Training Accuracy: 94.30%, Validation Loss: 0.4129, Validation Accuracy: 88.31%\n",
      "Epoch [26/200], Training Loss: 0.1769, Training Accuracy: 94.54%, Validation Loss: 0.4060, Validation Accuracy: 88.69%\n",
      "Epoch [27/200], Training Loss: 0.1710, Training Accuracy: 94.57%, Validation Loss: 0.4033, Validation Accuracy: 88.68%\n",
      "Epoch [28/200], Training Loss: 0.1712, Training Accuracy: 94.65%, Validation Loss: 0.4112, Validation Accuracy: 88.52%\n",
      "Epoch [29/200], Training Loss: 0.1727, Training Accuracy: 94.52%, Validation Loss: 0.4115, Validation Accuracy: 88.42%\n",
      "Epoch [30/200], Training Loss: 0.1709, Training Accuracy: 94.55%, Validation Loss: 0.4071, Validation Accuracy: 88.60%\n",
      "Epoch [31/200], Training Loss: 0.1666, Training Accuracy: 94.67%, Validation Loss: 0.4067, Validation Accuracy: 88.81%\n",
      "Epoch [32/200], Training Loss: 0.1655, Training Accuracy: 94.74%, Validation Loss: 0.4023, Validation Accuracy: 88.82%\n",
      "Epoch [33/200], Training Loss: 0.1667, Training Accuracy: 94.81%, Validation Loss: 0.4046, Validation Accuracy: 88.72%\n",
      "Epoch [34/200], Training Loss: 0.1646, Training Accuracy: 94.82%, Validation Loss: 0.4040, Validation Accuracy: 88.76%\n",
      "Epoch [35/200], Training Loss: 0.1614, Training Accuracy: 94.81%, Validation Loss: 0.4042, Validation Accuracy: 88.74%\n",
      "Epoch [36/200], Training Loss: 0.1661, Training Accuracy: 94.74%, Validation Loss: 0.4042, Validation Accuracy: 88.77%\n",
      "Epoch [37/200], Training Loss: 0.1616, Training Accuracy: 94.85%, Validation Loss: 0.4038, Validation Accuracy: 88.78%\n",
      "Early stopping at epoch 38\n",
      "Result - Validation Loss: 0.4038, Validation Accuracy: 88.78%\n",
      "\n",
      "Testing hyperparameter combination 185/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7568, Training Accuracy: 76.09%, Validation Loss: 0.7214, Validation Accuracy: 77.18%\n",
      "Epoch [2/200], Training Loss: 0.4835, Training Accuracy: 85.10%, Validation Loss: 0.6430, Validation Accuracy: 80.04%\n",
      "Epoch [3/200], Training Loss: 0.4198, Training Accuracy: 87.17%, Validation Loss: 0.5686, Validation Accuracy: 82.64%\n",
      "Epoch [4/200], Training Loss: 0.3803, Training Accuracy: 88.36%, Validation Loss: 0.5712, Validation Accuracy: 82.34%\n",
      "Epoch [5/200], Training Loss: 0.3554, Training Accuracy: 89.09%, Validation Loss: 0.5381, Validation Accuracy: 83.67%\n",
      "Epoch [6/200], Training Loss: 0.3337, Training Accuracy: 89.80%, Validation Loss: 0.5313, Validation Accuracy: 84.05%\n",
      "Epoch [7/200], Training Loss: 0.3185, Training Accuracy: 90.28%, Validation Loss: 0.5265, Validation Accuracy: 84.90%\n",
      "Epoch [8/200], Training Loss: 0.3049, Training Accuracy: 90.71%, Validation Loss: 0.5353, Validation Accuracy: 84.31%\n",
      "Epoch [9/200], Training Loss: 0.2958, Training Accuracy: 90.94%, Validation Loss: 0.5254, Validation Accuracy: 84.52%\n",
      "Epoch [10/200], Training Loss: 0.2841, Training Accuracy: 91.35%, Validation Loss: 0.4836, Validation Accuracy: 86.07%\n",
      "Epoch [11/200], Training Loss: 0.2808, Training Accuracy: 91.55%, Validation Loss: 0.4836, Validation Accuracy: 86.17%\n",
      "Epoch [12/200], Training Loss: 0.2737, Training Accuracy: 91.64%, Validation Loss: 0.4980, Validation Accuracy: 85.71%\n",
      "Epoch [13/200], Training Loss: 0.2639, Training Accuracy: 91.92%, Validation Loss: 0.4801, Validation Accuracy: 86.33%\n",
      "Epoch [14/200], Training Loss: 0.2596, Training Accuracy: 92.12%, Validation Loss: 0.4824, Validation Accuracy: 86.09%\n",
      "Epoch [15/200], Training Loss: 0.2522, Training Accuracy: 92.33%, Validation Loss: 0.4773, Validation Accuracy: 86.35%\n",
      "Epoch [16/200], Training Loss: 0.2502, Training Accuracy: 92.42%, Validation Loss: 0.4585, Validation Accuracy: 87.09%\n",
      "Epoch [17/200], Training Loss: 0.2438, Training Accuracy: 92.55%, Validation Loss: 0.4735, Validation Accuracy: 86.57%\n",
      "Epoch [18/200], Training Loss: 0.2397, Training Accuracy: 92.64%, Validation Loss: 0.4609, Validation Accuracy: 87.51%\n",
      "Epoch [19/200], Training Loss: 0.2415, Training Accuracy: 92.74%, Validation Loss: 0.4940, Validation Accuracy: 86.12%\n",
      "Epoch [20/200], Training Loss: 0.2361, Training Accuracy: 92.67%, Validation Loss: 0.4976, Validation Accuracy: 86.39%\n",
      "Epoch [21/200], Training Loss: 0.1873, Training Accuracy: 94.28%, Validation Loss: 0.4423, Validation Accuracy: 87.93%\n",
      "Epoch [22/200], Training Loss: 0.1731, Training Accuracy: 94.72%, Validation Loss: 0.4363, Validation Accuracy: 88.46%\n",
      "Epoch [23/200], Training Loss: 0.1685, Training Accuracy: 94.91%, Validation Loss: 0.4399, Validation Accuracy: 88.29%\n",
      "Epoch [24/200], Training Loss: 0.1638, Training Accuracy: 94.90%, Validation Loss: 0.4327, Validation Accuracy: 88.55%\n",
      "Epoch [25/200], Training Loss: 0.1590, Training Accuracy: 95.11%, Validation Loss: 0.4373, Validation Accuracy: 88.40%\n",
      "Epoch [26/200], Training Loss: 0.1634, Training Accuracy: 94.98%, Validation Loss: 0.4431, Validation Accuracy: 88.08%\n",
      "Epoch [27/200], Training Loss: 0.1564, Training Accuracy: 95.09%, Validation Loss: 0.4347, Validation Accuracy: 88.59%\n",
      "Epoch [28/200], Training Loss: 0.1583, Training Accuracy: 95.25%, Validation Loss: 0.4354, Validation Accuracy: 88.52%\n",
      "Epoch [29/200], Training Loss: 0.1472, Training Accuracy: 95.49%, Validation Loss: 0.4341, Validation Accuracy: 88.67%\n",
      "Early stopping at epoch 30\n",
      "Result - Validation Loss: 0.4341, Validation Accuracy: 88.67%\n",
      "\n",
      "Testing hyperparameter combination 186/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 16, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7354, Training Accuracy: 76.64%, Validation Loss: 0.7022, Validation Accuracy: 78.29%\n",
      "Epoch [2/200], Training Loss: 0.4852, Training Accuracy: 85.12%, Validation Loss: 0.6054, Validation Accuracy: 80.94%\n",
      "Epoch [3/200], Training Loss: 0.4177, Training Accuracy: 87.09%, Validation Loss: 0.5678, Validation Accuracy: 82.42%\n",
      "Epoch [4/200], Training Loss: 0.3855, Training Accuracy: 88.16%, Validation Loss: 0.5878, Validation Accuracy: 81.89%\n",
      "Epoch [5/200], Training Loss: 0.3644, Training Accuracy: 88.84%, Validation Loss: 0.5322, Validation Accuracy: 84.23%\n",
      "Epoch [6/200], Training Loss: 0.3434, Training Accuracy: 89.43%, Validation Loss: 0.5120, Validation Accuracy: 84.87%\n",
      "Epoch [7/200], Training Loss: 0.3246, Training Accuracy: 89.91%, Validation Loss: 0.5339, Validation Accuracy: 84.27%\n",
      "Epoch [8/200], Training Loss: 0.3204, Training Accuracy: 90.26%, Validation Loss: 0.5062, Validation Accuracy: 84.96%\n",
      "Epoch [9/200], Training Loss: 0.3096, Training Accuracy: 90.34%, Validation Loss: 0.4706, Validation Accuracy: 86.41%\n",
      "Epoch [10/200], Training Loss: 0.3026, Training Accuracy: 90.77%, Validation Loss: 0.4730, Validation Accuracy: 86.70%\n",
      "Epoch [11/200], Training Loss: 0.2972, Training Accuracy: 90.76%, Validation Loss: 0.5418, Validation Accuracy: 84.85%\n",
      "Epoch [12/200], Training Loss: 0.2948, Training Accuracy: 91.02%, Validation Loss: 0.5201, Validation Accuracy: 85.24%\n",
      "Epoch [13/200], Training Loss: 0.2834, Training Accuracy: 91.31%, Validation Loss: 0.4970, Validation Accuracy: 86.06%\n",
      "Epoch [14/200], Training Loss: 0.2233, Training Accuracy: 93.25%, Validation Loss: 0.4482, Validation Accuracy: 87.66%\n",
      "Epoch [15/200], Training Loss: 0.2116, Training Accuracy: 93.42%, Validation Loss: 0.4383, Validation Accuracy: 87.84%\n",
      "Epoch [16/200], Training Loss: 0.2082, Training Accuracy: 93.46%, Validation Loss: 0.4245, Validation Accuracy: 88.19%\n",
      "Epoch [17/200], Training Loss: 0.2004, Training Accuracy: 93.78%, Validation Loss: 0.4244, Validation Accuracy: 88.15%\n",
      "Epoch [18/200], Training Loss: 0.1960, Training Accuracy: 93.91%, Validation Loss: 0.4293, Validation Accuracy: 88.25%\n",
      "Epoch [19/200], Training Loss: 0.1974, Training Accuracy: 93.78%, Validation Loss: 0.4237, Validation Accuracy: 88.21%\n",
      "Epoch [20/200], Training Loss: 0.1933, Training Accuracy: 93.94%, Validation Loss: 0.4217, Validation Accuracy: 88.28%\n",
      "Epoch [21/200], Training Loss: 0.1927, Training Accuracy: 94.00%, Validation Loss: 0.4155, Validation Accuracy: 88.44%\n",
      "Epoch [22/200], Training Loss: 0.1915, Training Accuracy: 93.96%, Validation Loss: 0.4107, Validation Accuracy: 88.63%\n",
      "Epoch [23/200], Training Loss: 0.1889, Training Accuracy: 94.08%, Validation Loss: 0.4191, Validation Accuracy: 88.44%\n",
      "Epoch [24/200], Training Loss: 0.1886, Training Accuracy: 94.11%, Validation Loss: 0.4139, Validation Accuracy: 88.53%\n",
      "Epoch [25/200], Training Loss: 0.1858, Training Accuracy: 94.24%, Validation Loss: 0.4151, Validation Accuracy: 88.43%\n",
      "Epoch [26/200], Training Loss: 0.1892, Training Accuracy: 94.18%, Validation Loss: 0.4135, Validation Accuracy: 88.72%\n",
      "Epoch [27/200], Training Loss: 0.1774, Training Accuracy: 94.45%, Validation Loss: 0.4148, Validation Accuracy: 88.74%\n",
      "Early stopping at epoch 28\n",
      "Result - Validation Loss: 0.4148, Validation Accuracy: 88.74%\n",
      "\n",
      "Testing hyperparameter combination 187/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7790, Training Accuracy: 75.39%, Validation Loss: 0.7524, Validation Accuracy: 76.61%\n",
      "Epoch [2/200], Training Loss: 0.4851, Training Accuracy: 85.07%, Validation Loss: 0.6464, Validation Accuracy: 79.95%\n",
      "Epoch [3/200], Training Loss: 0.4037, Training Accuracy: 87.61%, Validation Loss: 0.5777, Validation Accuracy: 82.11%\n",
      "Epoch [4/200], Training Loss: 0.3664, Training Accuracy: 88.78%, Validation Loss: 0.5225, Validation Accuracy: 84.45%\n",
      "Epoch [5/200], Training Loss: 0.3393, Training Accuracy: 89.52%, Validation Loss: 0.5145, Validation Accuracy: 84.60%\n",
      "Epoch [6/200], Training Loss: 0.3195, Training Accuracy: 90.12%, Validation Loss: 0.4905, Validation Accuracy: 85.36%\n",
      "Epoch [7/200], Training Loss: 0.3052, Training Accuracy: 90.67%, Validation Loss: 0.4936, Validation Accuracy: 85.20%\n",
      "Epoch [8/200], Training Loss: 0.2953, Training Accuracy: 91.02%, Validation Loss: 0.5277, Validation Accuracy: 84.06%\n",
      "Epoch [9/200], Training Loss: 0.2846, Training Accuracy: 91.36%, Validation Loss: 0.5027, Validation Accuracy: 85.19%\n",
      "Epoch [10/200], Training Loss: 0.2778, Training Accuracy: 91.47%, Validation Loss: 0.4704, Validation Accuracy: 86.08%\n",
      "Epoch [11/200], Training Loss: 0.2657, Training Accuracy: 91.77%, Validation Loss: 0.4616, Validation Accuracy: 86.53%\n",
      "Epoch [12/200], Training Loss: 0.2593, Training Accuracy: 92.01%, Validation Loss: 0.4756, Validation Accuracy: 86.27%\n",
      "Epoch [13/200], Training Loss: 0.2522, Training Accuracy: 92.10%, Validation Loss: 0.4694, Validation Accuracy: 86.87%\n",
      "Epoch [14/200], Training Loss: 0.2448, Training Accuracy: 92.57%, Validation Loss: 0.4691, Validation Accuracy: 86.53%\n",
      "Epoch [15/200], Training Loss: 0.2404, Training Accuracy: 92.61%, Validation Loss: 0.4610, Validation Accuracy: 86.90%\n",
      "Epoch [16/200], Training Loss: 0.2364, Training Accuracy: 92.78%, Validation Loss: 0.4644, Validation Accuracy: 87.38%\n",
      "Epoch [17/200], Training Loss: 0.2304, Training Accuracy: 92.91%, Validation Loss: 0.4344, Validation Accuracy: 87.91%\n",
      "Epoch [18/200], Training Loss: 0.2268, Training Accuracy: 92.98%, Validation Loss: 0.4595, Validation Accuracy: 87.23%\n",
      "Epoch [19/200], Training Loss: 0.2245, Training Accuracy: 93.09%, Validation Loss: 0.4470, Validation Accuracy: 87.65%\n",
      "Epoch [20/200], Training Loss: 0.2176, Training Accuracy: 93.33%, Validation Loss: 0.4504, Validation Accuracy: 87.82%\n",
      "Epoch [21/200], Training Loss: 0.2189, Training Accuracy: 93.27%, Validation Loss: 0.4747, Validation Accuracy: 86.83%\n",
      "Epoch [22/200], Training Loss: 0.1761, Training Accuracy: 94.56%, Validation Loss: 0.4321, Validation Accuracy: 88.38%\n",
      "Epoch [23/200], Training Loss: 0.1640, Training Accuracy: 94.79%, Validation Loss: 0.4356, Validation Accuracy: 88.40%\n",
      "Epoch [24/200], Training Loss: 0.1591, Training Accuracy: 95.13%, Validation Loss: 0.4355, Validation Accuracy: 88.51%\n",
      "Epoch [25/200], Training Loss: 0.1620, Training Accuracy: 95.05%, Validation Loss: 0.4344, Validation Accuracy: 88.80%\n",
      "Epoch [26/200], Training Loss: 0.1565, Training Accuracy: 95.15%, Validation Loss: 0.4347, Validation Accuracy: 88.84%\n",
      "Epoch [27/200], Training Loss: 0.1520, Training Accuracy: 95.17%, Validation Loss: 0.4332, Validation Accuracy: 88.73%\n",
      "Early stopping at epoch 28\n",
      "Result - Validation Loss: 0.4332, Validation Accuracy: 88.73%\n",
      "\n",
      "Testing hyperparameter combination 188/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 32, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.7423, Training Accuracy: 76.59%, Validation Loss: 0.7079, Validation Accuracy: 77.40%\n",
      "Epoch [2/200], Training Loss: 0.4720, Training Accuracy: 85.34%, Validation Loss: 0.6473, Validation Accuracy: 79.84%\n",
      "Epoch [3/200], Training Loss: 0.4108, Training Accuracy: 87.28%, Validation Loss: 0.6125, Validation Accuracy: 81.10%\n",
      "Epoch [4/200], Training Loss: 0.3735, Training Accuracy: 88.42%, Validation Loss: 0.5655, Validation Accuracy: 82.80%\n",
      "Epoch [5/200], Training Loss: 0.3487, Training Accuracy: 89.17%, Validation Loss: 0.5267, Validation Accuracy: 84.13%\n",
      "Epoch [6/200], Training Loss: 0.3320, Training Accuracy: 89.69%, Validation Loss: 0.5345, Validation Accuracy: 83.82%\n",
      "Epoch [7/200], Training Loss: 0.3167, Training Accuracy: 90.20%, Validation Loss: 0.5102, Validation Accuracy: 84.86%\n",
      "Epoch [8/200], Training Loss: 0.3030, Training Accuracy: 90.70%, Validation Loss: 0.5382, Validation Accuracy: 83.98%\n",
      "Epoch [9/200], Training Loss: 0.2974, Training Accuracy: 90.76%, Validation Loss: 0.4764, Validation Accuracy: 85.89%\n",
      "Epoch [10/200], Training Loss: 0.2863, Training Accuracy: 91.13%, Validation Loss: 0.4738, Validation Accuracy: 85.95%\n",
      "Epoch [11/200], Training Loss: 0.2794, Training Accuracy: 91.44%, Validation Loss: 0.5166, Validation Accuracy: 85.32%\n",
      "Epoch [12/200], Training Loss: 0.2745, Training Accuracy: 91.39%, Validation Loss: 0.4852, Validation Accuracy: 85.86%\n",
      "Epoch [13/200], Training Loss: 0.2693, Training Accuracy: 91.66%, Validation Loss: 0.4592, Validation Accuracy: 86.22%\n",
      "Epoch [14/200], Training Loss: 0.2628, Training Accuracy: 91.83%, Validation Loss: 0.4874, Validation Accuracy: 85.97%\n",
      "Epoch [15/200], Training Loss: 0.2597, Training Accuracy: 91.91%, Validation Loss: 0.4681, Validation Accuracy: 86.13%\n",
      "Epoch [16/200], Training Loss: 0.2556, Training Accuracy: 92.08%, Validation Loss: 0.4800, Validation Accuracy: 86.19%\n",
      "Epoch [17/200], Training Loss: 0.2475, Training Accuracy: 92.28%, Validation Loss: 0.4627, Validation Accuracy: 86.60%\n",
      "Epoch [18/200], Training Loss: 0.2069, Training Accuracy: 93.48%, Validation Loss: 0.4368, Validation Accuracy: 87.79%\n",
      "Epoch [19/200], Training Loss: 0.1951, Training Accuracy: 93.80%, Validation Loss: 0.4258, Validation Accuracy: 88.08%\n",
      "Epoch [20/200], Training Loss: 0.1890, Training Accuracy: 94.13%, Validation Loss: 0.4289, Validation Accuracy: 87.99%\n",
      "Epoch [21/200], Training Loss: 0.1868, Training Accuracy: 94.24%, Validation Loss: 0.4264, Validation Accuracy: 88.00%\n",
      "Epoch [22/200], Training Loss: 0.1864, Training Accuracy: 94.14%, Validation Loss: 0.4190, Validation Accuracy: 88.28%\n",
      "Epoch [23/200], Training Loss: 0.1819, Training Accuracy: 94.20%, Validation Loss: 0.4150, Validation Accuracy: 88.25%\n",
      "Epoch [24/200], Training Loss: 0.1822, Training Accuracy: 94.26%, Validation Loss: 0.4226, Validation Accuracy: 88.31%\n",
      "Epoch [25/200], Training Loss: 0.1824, Training Accuracy: 94.39%, Validation Loss: 0.4225, Validation Accuracy: 88.35%\n",
      "Epoch [26/200], Training Loss: 0.1800, Training Accuracy: 94.34%, Validation Loss: 0.4117, Validation Accuracy: 88.46%\n",
      "Epoch [27/200], Training Loss: 0.1726, Training Accuracy: 94.49%, Validation Loss: 0.4120, Validation Accuracy: 88.48%\n",
      "Epoch [28/200], Training Loss: 0.1736, Training Accuracy: 94.70%, Validation Loss: 0.4207, Validation Accuracy: 88.25%\n",
      "Epoch [29/200], Training Loss: 0.1739, Training Accuracy: 94.54%, Validation Loss: 0.4189, Validation Accuracy: 88.38%\n",
      "Epoch [30/200], Training Loss: 0.1714, Training Accuracy: 94.57%, Validation Loss: 0.4170, Validation Accuracy: 88.46%\n",
      "Epoch [31/200], Training Loss: 0.1713, Training Accuracy: 94.61%, Validation Loss: 0.4144, Validation Accuracy: 88.50%\n",
      "Early stopping at epoch 32\n",
      "Result - Validation Loss: 0.4144, Validation Accuracy: 88.50%\n",
      "\n",
      "Testing hyperparameter combination 189/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.01, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n",
      "Epoch [1/200], Training Loss: 0.8228, Training Accuracy: 73.91%, Validation Loss: 0.7397, Validation Accuracy: 76.84%\n",
      "Epoch [2/200], Training Loss: 0.4891, Training Accuracy: 84.86%, Validation Loss: 0.6171, Validation Accuracy: 80.85%\n",
      "Epoch [3/200], Training Loss: 0.4133, Training Accuracy: 87.44%, Validation Loss: 0.5602, Validation Accuracy: 82.59%\n",
      "Epoch [4/200], Training Loss: 0.3599, Training Accuracy: 88.93%, Validation Loss: 0.5327, Validation Accuracy: 83.46%\n",
      "Epoch [5/200], Training Loss: 0.3353, Training Accuracy: 89.81%, Validation Loss: 0.4996, Validation Accuracy: 84.77%\n",
      "Epoch [6/200], Training Loss: 0.3171, Training Accuracy: 90.25%, Validation Loss: 0.5067, Validation Accuracy: 84.91%\n",
      "Epoch [7/200], Training Loss: 0.2976, Training Accuracy: 90.81%, Validation Loss: 0.4914, Validation Accuracy: 85.14%\n",
      "Epoch [8/200], Training Loss: 0.2899, Training Accuracy: 91.03%, Validation Loss: 0.4777, Validation Accuracy: 86.32%\n",
      "Epoch [9/200], Training Loss: 0.2738, Training Accuracy: 91.66%, Validation Loss: 0.4830, Validation Accuracy: 85.67%\n",
      "Epoch [10/200], Training Loss: 0.2684, Training Accuracy: 91.71%, Validation Loss: 0.4661, Validation Accuracy: 86.46%\n",
      "Epoch [11/200], Training Loss: 0.2547, Training Accuracy: 92.11%, Validation Loss: 0.4657, Validation Accuracy: 86.02%\n",
      "Epoch [12/200], Training Loss: 0.2493, Training Accuracy: 92.36%, Validation Loss: 0.4482, Validation Accuracy: 87.07%\n",
      "Epoch [13/200], Training Loss: 0.2496, Training Accuracy: 92.37%, Validation Loss: 0.4644, Validation Accuracy: 86.60%\n",
      "Epoch [14/200], Training Loss: 0.2360, Training Accuracy: 92.57%, Validation Loss: 0.4658, Validation Accuracy: 86.61%\n",
      "Epoch [15/200], Training Loss: 0.2301, Training Accuracy: 92.93%, Validation Loss: 0.4447, Validation Accuracy: 87.36%\n",
      "Epoch [16/200], Training Loss: 0.2277, Training Accuracy: 92.86%, Validation Loss: 0.4413, Validation Accuracy: 87.33%\n",
      "Epoch [17/200], Training Loss: 0.2244, Training Accuracy: 92.98%, Validation Loss: 0.4496, Validation Accuracy: 87.42%\n",
      "Epoch [18/200], Training Loss: 0.2217, Training Accuracy: 93.03%, Validation Loss: 0.4687, Validation Accuracy: 86.89%\n",
      "Epoch [19/200], Training Loss: 0.2122, Training Accuracy: 93.33%, Validation Loss: 0.4459, Validation Accuracy: 87.42%\n",
      "Epoch [20/200], Training Loss: 0.2096, Training Accuracy: 93.49%, Validation Loss: 0.4570, Validation Accuracy: 87.66%\n",
      "Epoch [21/200], Training Loss: 0.1697, Training Accuracy: 94.81%, Validation Loss: 0.4303, Validation Accuracy: 88.26%\n",
      "Epoch [22/200], Training Loss: 0.1620, Training Accuracy: 94.98%, Validation Loss: 0.4265, Validation Accuracy: 88.34%\n",
      "Epoch [23/200], Training Loss: 0.1595, Training Accuracy: 95.08%, Validation Loss: 0.4276, Validation Accuracy: 88.41%\n",
      "Epoch [24/200], Training Loss: 0.1623, Training Accuracy: 94.93%, Validation Loss: 0.4218, Validation Accuracy: 88.58%\n",
      "Epoch [25/200], Training Loss: 0.1591, Training Accuracy: 95.10%, Validation Loss: 0.4238, Validation Accuracy: 88.46%\n",
      "Epoch [26/200], Training Loss: 0.1525, Training Accuracy: 95.28%, Validation Loss: 0.4252, Validation Accuracy: 88.48%\n",
      "Epoch [27/200], Training Loss: 0.1536, Training Accuracy: 95.31%, Validation Loss: 0.4189, Validation Accuracy: 88.63%\n",
      "Epoch [28/200], Training Loss: 0.1533, Training Accuracy: 95.29%, Validation Loss: 0.4287, Validation Accuracy: 88.46%\n",
      "Epoch [29/200], Training Loss: 0.1500, Training Accuracy: 95.37%, Validation Loss: 0.4301, Validation Accuracy: 88.51%\n",
      "Epoch [30/200], Training Loss: 0.1500, Training Accuracy: 95.29%, Validation Loss: 0.4225, Validation Accuracy: 88.59%\n",
      "Epoch [31/200], Training Loss: 0.1480, Training Accuracy: 95.43%, Validation Loss: 0.4262, Validation Accuracy: 88.52%\n",
      "Epoch [32/200], Training Loss: 0.1461, Training Accuracy: 95.49%, Validation Loss: 0.4244, Validation Accuracy: 88.51%\n",
      "Early stopping at epoch 33\n",
      "Result - Validation Loss: 0.4244, Validation Accuracy: 88.51%\n",
      "\n",
      "Testing hyperparameter combination 190/2880: {'learning_rate': 0.001, 'layer_sizes': [128, 64], 'dropout_rates': [0.3, 0.3], 'batch_norm': [False, False], 'weight_decay': 0.001, 'batch_size': 64, 'leaky_relu_negative_slope': 0.1, 'num_epochs': 200, 'scheduler_mode': 'min', 'scheduler_factor': 0.1, 'scheduler_patience': 3, 'scheduler_threshold': 0.0001, 'scheduler_cooldown': 0, 'early_stopping_mode': 'min', 'early_stopping_patience': 5, 'early_stopping_delta': 0.0001}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 306\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# Call train_and_evaluate and record the computation time\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 306\u001b[0m     val_loss, val_accuracy, training_log, model, activation_functions, optimizer, scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    308\u001b[0m     computation_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[1], line 195\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m    192\u001b[0m correct_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    193\u001b[0m total_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 195\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/EEL/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import random\n",
    "from MLP_model import MLPClassifier  # Import the MLPClassifier class\n",
    "from itertools import product\n",
    "\n",
    "# Function to set all random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If you are using multi-GPU.\n",
    "    \n",
    "# Set the base seed\n",
    "set_seed(42)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Adjust if necessary\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image\n",
    "])\n",
    "\n",
    "# Load the KMNIST dataset\n",
    "train_dataset = datasets.KMNIST(root='../data', train=True, transform=transform, download=True)\n",
    "val_dataset = datasets.KMNIST(root='../data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Input and output sizes\n",
    "input_size = 784  # For 28x28 images\n",
    "output_size = 10  # Number of classes\n",
    "\n",
    "# Hyperparameter grid for tuning\n",
    "hyperparameter_grid = {\n",
    "    'learning_rate': [1e-3, 1e-4, 1e-5],\n",
    "    'layer_sizes': [[128, 64], [256, 128], [512, 256]],\n",
    "    'dropout_rates': [[0.1, 0.1], [0.2, 0.2], [0.3, 0.3], [0.4, 0.4], [0.5, 0.5]],\n",
    "    'batch_norm': [[True, True], [False, False]],\n",
    "    'weight_decay': [0.0, 1e-5, 1e-4, 1e-3],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'leaky_relu_negative_slope': [0.01, 0.1],  # Negative slope for LeakyReLU\n",
    "    'num_epochs': [200],  # Max number of training epochs\n",
    "    # ReduceLROnPlateau hyperparameters\n",
    "    'scheduler_mode': ['min'],  # Mode for the scheduler\n",
    "    'scheduler_factor': [0.1],  # Factor by which the learning rate will be reduced\n",
    "    'scheduler_patience': [3],  # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    'scheduler_threshold': [1e-4],  # Threshold for measuring the new optimum\n",
    "    'scheduler_cooldown': [0],  # Number of epochs to wait before resuming normal operation after lr has been reduced\n",
    "    # Early Stopping hyperparameters\n",
    "    'early_stopping_mode': ['min'],  # Mode for early stopping\n",
    "    'early_stopping_patience': [5],  # Patience for early stopping\n",
    "    'early_stopping_delta': [1e-4],  # Minimum change to qualify as improvement\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "keys, values = zip(*hyperparameter_grid.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "csv_filename = 'MLP_hyperparameter_tuning_results.csv'\n",
    "\n",
    "# Initialize an empty set to store hashes of existing results\n",
    "existing_hashes = set()\n",
    "\n",
    "# Initialize best_val_loss to infinity\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "if os.path.exists(csv_filename):\n",
    "    with open(csv_filename, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            hparams_hash = row['hparams_hash']\n",
    "            existing_hashes.add(hparams_hash)\n",
    "            try:\n",
    "                current_val_loss = float(row['val_loss'])\n",
    "                if current_val_loss < best_val_loss:\n",
    "                    best_val_loss = current_val_loss\n",
    "            except ValueError:\n",
    "                # Handle cases where val_loss might not be a valid float\n",
    "                continue\n",
    "    print(f\"Existing best validation loss from CSV: {best_val_loss:.4f}\")\n",
    "else:\n",
    "    print(\"CSV file does not exist. Starting fresh.\")\n",
    "    # If the file does not exist, we'll create it later\n",
    "\n",
    "def train_and_evaluate(hparams):\n",
    "    # Unpack hyperparameters\n",
    "    learning_rate = hparams['learning_rate']\n",
    "    layer_sizes = hparams['layer_sizes']\n",
    "    dropout_rates = hparams['dropout_rates']\n",
    "    batch_norm = hparams['batch_norm']\n",
    "    weight_decay = hparams['weight_decay']\n",
    "    batch_size = hparams['batch_size']\n",
    "    leaky_relu_negative_slope = hparams['leaky_relu_negative_slope']\n",
    "    num_epochs = hparams.get('num_epochs', 50)\n",
    "    \n",
    "    # Scheduler hyperparameters\n",
    "    scheduler_mode = hparams['scheduler_mode']\n",
    "    scheduler_factor = hparams['scheduler_factor']\n",
    "    scheduler_patience = hparams['scheduler_patience']\n",
    "    scheduler_threshold = hparams['scheduler_threshold']\n",
    "    scheduler_cooldown = hparams['scheduler_cooldown']\n",
    "    \n",
    "    # Early Stopping hyperparameters\n",
    "    early_stopping_mode = hparams['early_stopping_mode']\n",
    "    early_stopping_patience = hparams['early_stopping_patience']\n",
    "    early_stopping_delta = hparams['early_stopping_delta']\n",
    "    \n",
    "    # Define activation functions: Always LeakyReLU with specified negative slope\n",
    "    activation_functions = [nn.LeakyReLU(negative_slope=leaky_relu_negative_slope) for _ in layer_sizes]\n",
    "\n",
    "    # Initialize the model\n",
    "    model = MLPClassifier(\n",
    "        input_size=input_size,\n",
    "        layer_sizes=layer_sizes,\n",
    "        output_size=output_size,\n",
    "        activation_functions=activation_functions,\n",
    "        dropout_rates=dropout_rates,\n",
    "        batch_norm=batch_norm,\n",
    "        weight_init=init_weights\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer (always AdamW)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler: ReduceLROnPlateau\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=scheduler_mode,\n",
    "        factor=scheduler_factor,\n",
    "        patience=scheduler_patience,\n",
    "        threshold=scheduler_threshold,\n",
    "        threshold_mode='rel',\n",
    "        cooldown=scheduler_cooldown,\n",
    "    )\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Early Stopping variables\n",
    "    best_metric = None\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "\n",
    "    # Determine the comparison operator based on mode\n",
    "    if early_stopping_mode == 'min':\n",
    "        def is_improvement(current, best):\n",
    "            return current < best - early_stopping_delta\n",
    "        best_metric = float('inf')\n",
    "    elif early_stopping_mode == 'max':\n",
    "        def is_improvement(current, best):\n",
    "            return current > best + early_stopping_delta\n",
    "        best_metric = float('-inf')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported early_stopping_mode: {early_stopping_mode}\")\n",
    "\n",
    "    # Initialize variables for logging\n",
    "    initial_lr = optimizer.param_groups[0]['lr']\n",
    "    current_lr = initial_lr\n",
    "    lr_reduction_epochs = []\n",
    "    epoch_logs = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Scheduler step: ReduceLROnPlateau expects a metric to monitor\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Check if learning rate has been reduced\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr < current_lr:\n",
    "            lr_reduction_epochs.append(epoch+1)  # Epochs are 1-indexed\n",
    "            current_lr = new_lr\n",
    "\n",
    "        # Record per-epoch logs\n",
    "        epoch_logs.append({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'learning_rate': current_lr\n",
    "        })\n",
    "\n",
    "        # Early Stopping check\n",
    "        if is_improvement(val_loss, best_metric):\n",
    "            best_metric = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            early_stop = True\n",
    "\n",
    "        # Optionally, print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Prepare training log\n",
    "    training_log = {\n",
    "        'final_epoch': epoch+1,\n",
    "        'lr_reduction_epochs': lr_reduction_epochs,\n",
    "        'epoch_logs': epoch_logs\n",
    "    }\n",
    "\n",
    "    # Return final validation loss and accuracy, training log, and the model\n",
    "    return val_loss, val_accuracy, training_log, model, activation_functions, optimizer, scheduler\n",
    "\n",
    "# Main loop for hyperparameter tuning\n",
    "results = []\n",
    "\n",
    "for idx, hparams in enumerate(hyperparameter_combinations):\n",
    "    # Set the base seed\n",
    "    set_seed(42)\n",
    "    # Generate a unique id for the hyperparameters\n",
    "    hparams_str = json.dumps(hparams, sort_keys=True)\n",
    "    hparams_hash = hashlib.md5(hparams_str.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    # Check if this combination exists in existing_results\n",
    "    if hparams_hash in existing_hashes:\n",
    "        print(f\"Skipping hyperparameter combination {idx+1}/{len(hyperparameter_combinations)}: {hparams} (already tested)\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Testing hyperparameter combination {idx+1}/{len(hyperparameter_combinations)}: {hparams}\")\n",
    "        try:\n",
    "            # Call train_and_evaluate and record the computation time\n",
    "            start_time = time.time()\n",
    "            val_loss, val_accuracy, training_log, model, activation_functions, optimizer, scheduler = train_and_evaluate(hparams)\n",
    "            end_time = time.time()\n",
    "            computation_time = end_time - start_time\n",
    "\n",
    "            # Save the per-epoch logs to a file\n",
    "            log_filename = f\"misc/training_log_{hparams_hash}.json\"\n",
    "            with open(log_filename, 'w') as f:\n",
    "                json.dump(training_log, f)\n",
    "            \n",
    "            # Append the result to the CSV file\n",
    "            with open(csv_filename, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['hparams_hash'] + list(hparams.keys()) + ['val_loss', 'val_accuracy', 'computation_time', 'final_num_epochs', 'lr_reduction_epochs', 'log_filename']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                # If the file is new, write the header\n",
    "                if csvfile.tell() == 0:\n",
    "                    writer.writeheader()\n",
    "                result_row = {'hparams_hash': hparams_hash}\n",
    "                for key, value in hparams.items():\n",
    "                    # Convert value to string using json.dumps\n",
    "                    result_row[key] = json.dumps(value)\n",
    "                result_row.update({\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'computation_time': computation_time,\n",
    "                    'final_num_epochs': training_log['final_epoch'],\n",
    "                    'lr_reduction_epochs': json.dumps(training_log['lr_reduction_epochs']),\n",
    "                    'log_filename': log_filename\n",
    "                })\n",
    "                writer.writerow(result_row)\n",
    "\n",
    "            # Update the set of existing hashes\n",
    "            existing_hashes.add(hparams_hash)\n",
    "\n",
    "            # Check if current val_loss is better than the best_val_loss\n",
    "            if val_loss < best_val_loss: \n",
    "                best_val_loss = val_loss\n",
    "                # Save the model's state_dict\n",
    "                best_model_filename = 'MLP_best_model.pth'\n",
    "                # Prepare all necessary information for saving\n",
    "                save_data = {\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'model_config': {\n",
    "                        'input_size': input_size,\n",
    "                        'output_size': output_size,\n",
    "                        'layer_sizes': hparams['layer_sizes'],\n",
    "                        'activation_functions': [str(type(act)) for act in activation_functions],\n",
    "                        'dropout_rates': hparams['dropout_rates'],\n",
    "                        'batch_norm': hparams['batch_norm'],\n",
    "                    },\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),  # Save optimizer state if needed for resuming training\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),  # Save scheduler state if used\n",
    "                    'hyperparameters': hparams,  # Save the hyperparameters for reference\n",
    "                    'training_log': training_log  # Include the training log if desired\n",
    "                }\n",
    "\n",
    "                # Save to file\n",
    "                torch.save(save_data, best_model_filename)\n",
    "                print(f\"New best model saved to {best_model_filename} with validation loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Append to results for final reporting\n",
    "            results.append({'hparams': hparams, 'val_loss': val_loss, 'val_accuracy': val_accuracy})\n",
    "            print(f\"Result - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with hyperparameters {hparams}: {e}\\n\")\n",
    "            continue\n",
    "\n",
    "# Find the best hyperparameters based on validation accuracy\n",
    "if results:\n",
    "    best_result = min(results, key=lambda x: x['val_loss'])  # Changed to min based on val_loss\n",
    "    print(\"Best hyperparameters based on validation loss:\")\n",
    "    print(best_result['hparams'])\n",
    "    print(f\"Validation Loss: {best_result['val_loss']:.4f}, Validation Accuracy: {best_result['val_accuracy']:.2f}%\")\n",
    "else:\n",
    "    print(\"No results to report.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
