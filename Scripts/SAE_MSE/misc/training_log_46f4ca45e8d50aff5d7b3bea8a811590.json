{"final_epoch": 90, "lr_reduction_epochs": [56, 78], "epoch_logs": [{"epoch": 1, "train_loss": 0.3681188307444255, "val_loss": 0.27680716080406603, "learning_rate": 0.001}, {"epoch": 2, "train_loss": 0.3235151381333669, "val_loss": 0.2562940743403694, "learning_rate": 0.001}, {"epoch": 3, "train_loss": 0.31050913076400755, "val_loss": 0.2441861879901764, "learning_rate": 0.001}, {"epoch": 4, "train_loss": 0.3017716860771179, "val_loss": 0.23387815334355108, "learning_rate": 0.001}, {"epoch": 5, "train_loss": 0.2958162809054057, "val_loss": 0.22784803555415462, "learning_rate": 0.001}, {"epoch": 6, "train_loss": 0.29082421743075054, "val_loss": 0.2222698788387707, "learning_rate": 0.001}, {"epoch": 7, "train_loss": 0.2870320988734563, "val_loss": 0.2179258955648532, "learning_rate": 0.001}, {"epoch": 8, "train_loss": 0.2837895585536957, "val_loss": 0.21490905088738513, "learning_rate": 0.001}, {"epoch": 9, "train_loss": 0.28110692716439567, "val_loss": 0.21129201800107195, "learning_rate": 0.001}, {"epoch": 10, "train_loss": 0.2790228445212046, "val_loss": 0.2081241565771377, "learning_rate": 0.001}, {"epoch": 11, "train_loss": 0.27677668648560844, "val_loss": 0.2043776302196728, "learning_rate": 0.001}, {"epoch": 12, "train_loss": 0.2751551498572032, "val_loss": 0.2045567320844236, "learning_rate": 0.001}, {"epoch": 13, "train_loss": 0.27352455322742464, "val_loss": 0.20041818531176533, "learning_rate": 0.001}, {"epoch": 14, "train_loss": 0.2722166614850362, "val_loss": 0.19890333150331965, "learning_rate": 0.001}, {"epoch": 15, "train_loss": 0.27100663150946297, "val_loss": 0.19711933820582808, "learning_rate": 0.001}, {"epoch": 16, "train_loss": 0.2698610968430837, "val_loss": 0.19657722534463049, "learning_rate": 0.001}, {"epoch": 17, "train_loss": 0.26889886412620545, "val_loss": 0.19514605588615894, "learning_rate": 0.001}, {"epoch": 18, "train_loss": 0.26813638525803885, "val_loss": 0.19326022610115928, "learning_rate": 0.001}, {"epoch": 19, "train_loss": 0.26727601770559944, "val_loss": 0.192830704890501, "learning_rate": 0.001}, {"epoch": 20, "train_loss": 0.2665077918847402, "val_loss": 0.19149241960658053, "learning_rate": 0.001}, {"epoch": 21, "train_loss": 0.2658606222629547, "val_loss": 0.19111468435857243, "learning_rate": 0.001}, {"epoch": 22, "train_loss": 0.26522402288118996, "val_loss": 0.1912301645016137, "learning_rate": 0.001}, {"epoch": 23, "train_loss": 0.2646824508587519, "val_loss": 0.1894468838414445, "learning_rate": 0.001}, {"epoch": 24, "train_loss": 0.2641954252799352, "val_loss": 0.18931489178357414, "learning_rate": 0.001}, {"epoch": 25, "train_loss": 0.26376815485954286, "val_loss": 0.18846786303070787, "learning_rate": 0.001}, {"epoch": 26, "train_loss": 0.2631449678500493, "val_loss": 0.18881218582867815, "learning_rate": 0.001}, {"epoch": 27, "train_loss": 0.26288475473721823, "val_loss": 0.18927168769958302, "learning_rate": 0.001}, {"epoch": 28, "train_loss": 0.26233447433312734, "val_loss": 0.18771852053011567, "learning_rate": 0.001}, {"epoch": 29, "train_loss": 0.2617175191561381, "val_loss": 0.1870941380723216, "learning_rate": 0.001}, {"epoch": 30, "train_loss": 0.26168027549584705, "val_loss": 0.1879160860761667, "learning_rate": 0.001}, {"epoch": 31, "train_loss": 0.26116060585180917, "val_loss": 0.1864070608116948, "learning_rate": 0.001}, {"epoch": 32, "train_loss": 0.260894322013855, "val_loss": 0.1856771773709276, "learning_rate": 0.001}, {"epoch": 33, "train_loss": 0.2605150100628535, "val_loss": 0.18472171829531367, "learning_rate": 0.001}, {"epoch": 34, "train_loss": 0.2601617665449778, "val_loss": 0.18509258644078105, "learning_rate": 0.001}, {"epoch": 35, "train_loss": 0.25998940890630085, "val_loss": 0.18534326015379482, "learning_rate": 0.001}, {"epoch": 36, "train_loss": 0.2595918042580287, "val_loss": 0.18412599229393675, "learning_rate": 0.001}, {"epoch": 37, "train_loss": 0.25954853203296663, "val_loss": 0.18426191273588724, "learning_rate": 0.001}, {"epoch": 38, "train_loss": 0.2593112210671107, "val_loss": 0.1831506578305278, "learning_rate": 0.001}, {"epoch": 39, "train_loss": 0.2588345644791921, "val_loss": 0.182984292364349, "learning_rate": 0.001}, {"epoch": 40, "train_loss": 0.25872856916586556, "val_loss": 0.18394439260418805, "learning_rate": 0.001}, {"epoch": 41, "train_loss": 0.25868014431794484, "val_loss": 0.1822966051558717, "learning_rate": 0.001}, {"epoch": 42, "train_loss": 0.2582148426294327, "val_loss": 0.18267491807381567, "learning_rate": 0.001}, {"epoch": 43, "train_loss": 0.2581852410475413, "val_loss": 0.18236105272564263, "learning_rate": 0.001}, {"epoch": 44, "train_loss": 0.2582292920430501, "val_loss": 0.18236590955204096, "learning_rate": 0.001}, {"epoch": 45, "train_loss": 0.257875573015213, "val_loss": 0.18146082539908803, "learning_rate": 0.001}, {"epoch": 46, "train_loss": 0.257376012412707, "val_loss": 0.18061691817765038, "learning_rate": 0.001}, {"epoch": 47, "train_loss": 0.25740669513543446, "val_loss": 0.18145568164202353, "learning_rate": 0.001}, {"epoch": 48, "train_loss": 0.257145205505689, "val_loss": 0.18137353015974306, "learning_rate": 0.001}, {"epoch": 49, "train_loss": 0.25700662302970884, "val_loss": 0.18064869388033405, "learning_rate": 0.001}, {"epoch": 50, "train_loss": 0.2568652680079142, "val_loss": 0.18004152635796764, "learning_rate": 0.001}, {"epoch": 51, "train_loss": 0.2569057610352834, "val_loss": 0.180048954563019, "learning_rate": 0.001}, {"epoch": 52, "train_loss": 0.256726540573438, "val_loss": 0.17878895821853186, "learning_rate": 0.001}, {"epoch": 53, "train_loss": 0.25645769845644634, "val_loss": 0.17991646262593924, "learning_rate": 0.001}, {"epoch": 54, "train_loss": 0.25624515204429626, "val_loss": 0.18033468618560522, "learning_rate": 0.001}, {"epoch": 55, "train_loss": 0.2561667194922765, "val_loss": 0.18035767872493488, "learning_rate": 0.001}, {"epoch": 56, "train_loss": 0.25601489301522573, "val_loss": 0.17975167458811506, "learning_rate": 0.0001}, {"epoch": 57, "train_loss": 0.24738894941806794, "val_loss": 0.16970218341952314, "learning_rate": 0.0001}, {"epoch": 58, "train_loss": 0.24547539936701457, "val_loss": 0.16854461399130166, "learning_rate": 0.0001}, {"epoch": 59, "train_loss": 0.2447241431236267, "val_loss": 0.16807214177835483, "learning_rate": 0.0001}, {"epoch": 60, "train_loss": 0.24437502517700196, "val_loss": 0.16818530467181161, "learning_rate": 0.0001}, {"epoch": 61, "train_loss": 0.24403239314556122, "val_loss": 0.16795832870867305, "learning_rate": 0.0001}, {"epoch": 62, "train_loss": 0.2440765498081843, "val_loss": 0.16775339451460794, "learning_rate": 0.0001}, {"epoch": 63, "train_loss": 0.24370182592074077, "val_loss": 0.16754077812924553, "learning_rate": 0.0001}, {"epoch": 64, "train_loss": 0.2435357633113861, "val_loss": 0.16745415582253148, "learning_rate": 0.0001}, {"epoch": 65, "train_loss": 0.24366181054115296, "val_loss": 0.16762205472769448, "learning_rate": 0.0001}, {"epoch": 66, "train_loss": 0.2431177426258723, "val_loss": 0.16718557957833569, "learning_rate": 0.0001}, {"epoch": 67, "train_loss": 0.24307535506089528, "val_loss": 0.1670144041315816, "learning_rate": 0.0001}, {"epoch": 68, "train_loss": 0.24296750044822693, "val_loss": 0.16689458908364416, "learning_rate": 0.0001}, {"epoch": 69, "train_loss": 0.2429323030869166, "val_loss": 0.16697908361879782, "learning_rate": 0.0001}, {"epoch": 70, "train_loss": 0.2429527229785919, "val_loss": 0.16738007581843356, "learning_rate": 0.0001}, {"epoch": 71, "train_loss": 0.2429165681441625, "val_loss": 0.16664915748488027, "learning_rate": 0.0001}, {"epoch": 72, "train_loss": 0.2427668681939443, "val_loss": 0.1666215919077206, "learning_rate": 0.0001}, {"epoch": 73, "train_loss": 0.2425649736483892, "val_loss": 0.16645815068730913, "learning_rate": 0.0001}, {"epoch": 74, "train_loss": 0.24280226383209227, "val_loss": 0.16624466446451486, "learning_rate": 0.0001}, {"epoch": 75, "train_loss": 0.24243177134990693, "val_loss": 0.16643424903432402, "learning_rate": 0.0001}, {"epoch": 76, "train_loss": 0.24233906371593475, "val_loss": 0.16634245859548308, "learning_rate": 0.0001}, {"epoch": 77, "train_loss": 0.24227350019613902, "val_loss": 0.1663559454793747, "learning_rate": 0.0001}, {"epoch": 78, "train_loss": 0.24228430840174356, "val_loss": 0.166451845734645, "learning_rate": 1e-05}, {"epoch": 79, "train_loss": 0.24161441887219748, "val_loss": 0.16560281955967315, "learning_rate": 1e-05}, {"epoch": 80, "train_loss": 0.24148844482898713, "val_loss": 0.16550744898593464, "learning_rate": 1e-05}, {"epoch": 81, "train_loss": 0.24127155326207478, "val_loss": 0.1654581939355253, "learning_rate": 1e-05}, {"epoch": 82, "train_loss": 0.24111710114479065, "val_loss": 0.16543863242426618, "learning_rate": 1e-05}, {"epoch": 83, "train_loss": 0.2410480267683665, "val_loss": 0.16541344070206054, "learning_rate": 1e-05}, {"epoch": 84, "train_loss": 0.2410892637570699, "val_loss": 0.16527751121467676, "learning_rate": 1e-05}, {"epoch": 85, "train_loss": 0.24137005964120228, "val_loss": 0.1653567794888926, "learning_rate": 1e-05}, {"epoch": 86, "train_loss": 0.24119527998765308, "val_loss": 0.16521385997629012, "learning_rate": 1e-05}, {"epoch": 87, "train_loss": 0.2411924753745397, "val_loss": 0.16531569598772275, "learning_rate": 1e-05}, {"epoch": 88, "train_loss": 0.241121395222346, "val_loss": 0.16530264980686357, "learning_rate": 1e-05}, {"epoch": 89, "train_loss": 0.2410606270869573, "val_loss": 0.16523506670904617, "learning_rate": 1e-05}]}