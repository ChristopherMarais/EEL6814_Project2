{"final_epoch": 114, "lr_reduction_epochs": [98], "epoch_logs": [{"epoch": 1, "train_loss": 0.4265704331800456, "val_loss": 0.3039464671400529, "learning_rate": 0.001}, {"epoch": 2, "train_loss": 0.35124543728425983, "val_loss": 0.27318000755732574, "learning_rate": 0.001}, {"epoch": 3, "train_loss": 0.33297145945946577, "val_loss": 0.25652886870541153, "learning_rate": 0.001}, {"epoch": 4, "train_loss": 0.32228063203184804, "val_loss": 0.24536787369583227, "learning_rate": 0.001}, {"epoch": 5, "train_loss": 0.3141035926159081, "val_loss": 0.23866247715829295, "learning_rate": 0.001}, {"epoch": 6, "train_loss": 0.30742720447842725, "val_loss": 0.23089142313486413, "learning_rate": 0.001}, {"epoch": 7, "train_loss": 0.3017837999726805, "val_loss": 0.2236747730381881, "learning_rate": 0.001}, {"epoch": 8, "train_loss": 0.2967976684612996, "val_loss": 0.21785223899008352, "learning_rate": 0.001}, {"epoch": 9, "train_loss": 0.29270851436783285, "val_loss": 0.21172943994214263, "learning_rate": 0.001}, {"epoch": 10, "train_loss": 0.2890765157806904, "val_loss": 0.208492325076574, "learning_rate": 0.001}, {"epoch": 11, "train_loss": 0.2860719797861241, "val_loss": 0.20402801753599434, "learning_rate": 0.001}, {"epoch": 12, "train_loss": 0.28324008010842305, "val_loss": 0.20140687574314164, "learning_rate": 0.001}, {"epoch": 13, "train_loss": 0.2809925061814925, "val_loss": 0.19851213127751893, "learning_rate": 0.001}, {"epoch": 14, "train_loss": 0.2789610000827428, "val_loss": 0.19678968983360484, "learning_rate": 0.001}, {"epoch": 15, "train_loss": 0.2773219679322694, "val_loss": 0.19513249020033244, "learning_rate": 0.001}, {"epoch": 16, "train_loss": 0.27564680530592, "val_loss": 0.192006324099589, "learning_rate": 0.001}, {"epoch": 17, "train_loss": 0.27439800156351857, "val_loss": 0.19188408063182347, "learning_rate": 0.001}, {"epoch": 18, "train_loss": 0.27310032300327136, "val_loss": 0.1895313504375989, "learning_rate": 0.001}, {"epoch": 19, "train_loss": 0.2716722292515933, "val_loss": 0.1883603509845613, "learning_rate": 0.001}, {"epoch": 20, "train_loss": 0.27074308521912227, "val_loss": 0.18653330093697656, "learning_rate": 0.001}, {"epoch": 21, "train_loss": 0.269788139616437, "val_loss": 0.1851811818306959, "learning_rate": 0.001}, {"epoch": 22, "train_loss": 0.26871855949501855, "val_loss": 0.1841176008876366, "learning_rate": 0.001}, {"epoch": 23, "train_loss": 0.2677313648831204, "val_loss": 0.18332399295855173, "learning_rate": 0.001}, {"epoch": 24, "train_loss": 0.2671707479087898, "val_loss": 0.18212082548232017, "learning_rate": 0.001}, {"epoch": 25, "train_loss": 0.26617941710040394, "val_loss": 0.18232665163806722, "learning_rate": 0.001}, {"epoch": 26, "train_loss": 0.2656471615709612, "val_loss": 0.18121140233323543, "learning_rate": 0.001}, {"epoch": 27, "train_loss": 0.26505172062103094, "val_loss": 0.18045019688485545, "learning_rate": 0.001}, {"epoch": 28, "train_loss": 0.26423287140134044, "val_loss": 0.17946226083779637, "learning_rate": 0.001}, {"epoch": 29, "train_loss": 0.2636378344977298, "val_loss": 0.17799106730690487, "learning_rate": 0.001}, {"epoch": 30, "train_loss": 0.263111112520213, "val_loss": 0.17836310044874118, "learning_rate": 0.001}, {"epoch": 31, "train_loss": 0.2625986564799648, "val_loss": 0.17693688503549068, "learning_rate": 0.001}, {"epoch": 32, "train_loss": 0.26198147263978144, "val_loss": 0.1756414331590073, "learning_rate": 0.001}, {"epoch": 33, "train_loss": 0.2615992283577199, "val_loss": 0.17497441097150876, "learning_rate": 0.001}, {"epoch": 34, "train_loss": 0.2612857766011182, "val_loss": 0.17444531940206698, "learning_rate": 0.001}, {"epoch": 35, "train_loss": 0.26075923217989294, "val_loss": 0.17461513793921168, "learning_rate": 0.001}, {"epoch": 36, "train_loss": 0.2601987985546327, "val_loss": 0.17303244562088688, "learning_rate": 0.001}, {"epoch": 37, "train_loss": 0.2596485851061009, "val_loss": 0.17259367715708818, "learning_rate": 0.001}, {"epoch": 38, "train_loss": 0.2594860960989047, "val_loss": 0.1729013046509103, "learning_rate": 0.001}, {"epoch": 39, "train_loss": 0.2589447149992599, "val_loss": 0.17199770257442812, "learning_rate": 0.001}, {"epoch": 40, "train_loss": 0.2586403175464372, "val_loss": 0.17172976762433595, "learning_rate": 0.001}, {"epoch": 41, "train_loss": 0.2582473466387185, "val_loss": 0.1703561602891246, "learning_rate": 0.001}, {"epoch": 42, "train_loss": 0.257977777163086, "val_loss": 0.17036081907115405, "learning_rate": 0.001}, {"epoch": 43, "train_loss": 0.2576136953004486, "val_loss": 0.16924547903899906, "learning_rate": 0.001}, {"epoch": 44, "train_loss": 0.2573026537209216, "val_loss": 0.16942339211325103, "learning_rate": 0.001}, {"epoch": 45, "train_loss": 0.2570966821344917, "val_loss": 0.16880742771716056, "learning_rate": 0.001}, {"epoch": 46, "train_loss": 0.2565148793294302, "val_loss": 0.16882694012756588, "learning_rate": 0.001}, {"epoch": 47, "train_loss": 0.2563433226417093, "val_loss": 0.16798582295828227, "learning_rate": 0.001}, {"epoch": 48, "train_loss": 0.25608639857348275, "val_loss": 0.1681190615967859, "learning_rate": 0.001}, {"epoch": 49, "train_loss": 0.2559371185119805, "val_loss": 0.16809137731413298, "learning_rate": 0.001}, {"epoch": 50, "train_loss": 0.25579228288377337, "val_loss": 0.167601328673242, "learning_rate": 0.001}, {"epoch": 51, "train_loss": 0.25530528450560996, "val_loss": 0.16747186832790134, "learning_rate": 0.001}, {"epoch": 52, "train_loss": 0.25487030101249286, "val_loss": 0.16645109728921817, "learning_rate": 0.001}, {"epoch": 53, "train_loss": 0.25473682620488775, "val_loss": 0.1658875870553753, "learning_rate": 0.001}, {"epoch": 54, "train_loss": 0.2544714532163747, "val_loss": 0.1659069287626049, "learning_rate": 0.001}, {"epoch": 55, "train_loss": 0.25458290788066357, "val_loss": 0.16577962059763413, "learning_rate": 0.001}, {"epoch": 56, "train_loss": 0.2543321448137693, "val_loss": 0.16557871861548362, "learning_rate": 0.001}, {"epoch": 57, "train_loss": 0.25394535529643986, "val_loss": 0.16544961514352244, "learning_rate": 0.001}, {"epoch": 58, "train_loss": 0.25375336259984604, "val_loss": 0.16512876654727549, "learning_rate": 0.001}, {"epoch": 59, "train_loss": 0.25384120448775915, "val_loss": 0.16417429945136927, "learning_rate": 0.001}, {"epoch": 60, "train_loss": 0.253500733877082, "val_loss": 0.1645305354761172, "learning_rate": 0.001}, {"epoch": 61, "train_loss": 0.25318843019587917, "val_loss": 0.16328736856768403, "learning_rate": 0.001}, {"epoch": 62, "train_loss": 0.25309281340797846, "val_loss": 0.1641695708790912, "learning_rate": 0.001}, {"epoch": 63, "train_loss": 0.2528076678362039, "val_loss": 0.16314205979999108, "learning_rate": 0.001}, {"epoch": 64, "train_loss": 0.2524530315185752, "val_loss": 0.16390258526500268, "learning_rate": 0.001}, {"epoch": 65, "train_loss": 0.25240144099268463, "val_loss": 0.16292414163486868, "learning_rate": 0.001}, {"epoch": 66, "train_loss": 0.25221901747119396, "val_loss": 0.16267406261419948, "learning_rate": 0.001}, {"epoch": 67, "train_loss": 0.2522214423207676, "val_loss": 0.16243137155152573, "learning_rate": 0.001}, {"epoch": 68, "train_loss": 0.2516347570035159, "val_loss": 0.16276686233055743, "learning_rate": 0.001}, {"epoch": 69, "train_loss": 0.25169125713808155, "val_loss": 0.1620908243746697, "learning_rate": 0.001}, {"epoch": 70, "train_loss": 0.25165809770984116, "val_loss": 0.1620541422427455, "learning_rate": 0.001}, {"epoch": 71, "train_loss": 0.25140357943599484, "val_loss": 0.16167253331293033, "learning_rate": 0.001}, {"epoch": 72, "train_loss": 0.2513806612595268, "val_loss": 0.16185823724239687, "learning_rate": 0.001}, {"epoch": 73, "train_loss": 0.25097278968604936, "val_loss": 0.16226756912243517, "learning_rate": 0.001}, {"epoch": 74, "train_loss": 0.250774144554687, "val_loss": 0.1612617041491255, "learning_rate": 0.001}, {"epoch": 75, "train_loss": 0.25102223398740336, "val_loss": 0.16031646709653397, "learning_rate": 0.001}, {"epoch": 76, "train_loss": 0.2505863742602756, "val_loss": 0.16103029137925257, "learning_rate": 0.001}, {"epoch": 77, "train_loss": 0.25057999439099254, "val_loss": 0.16062634051600588, "learning_rate": 0.001}, {"epoch": 78, "train_loss": 0.25019955840866887, "val_loss": 0.16004662517505355, "learning_rate": 0.001}, {"epoch": 79, "train_loss": 0.25032992348494126, "val_loss": 0.16002415931677516, "learning_rate": 0.001}, {"epoch": 80, "train_loss": 0.2501006337916455, "val_loss": 0.16004483137704148, "learning_rate": 0.001}, {"epoch": 81, "train_loss": 0.2499346832180267, "val_loss": 0.15951879058457627, "learning_rate": 0.001}, {"epoch": 82, "train_loss": 0.24955568384483953, "val_loss": 0.15985858063154582, "learning_rate": 0.001}, {"epoch": 83, "train_loss": 0.24960574282862036, "val_loss": 0.15961747437338286, "learning_rate": 0.001}, {"epoch": 84, "train_loss": 0.24948999327619362, "val_loss": 0.1595522312423851, "learning_rate": 0.001}, {"epoch": 85, "train_loss": 0.24939904863114856, "val_loss": 0.15943608800821665, "learning_rate": 0.001}, {"epoch": 86, "train_loss": 0.24905573982564386, "val_loss": 0.15884952643249609, "learning_rate": 0.001}, {"epoch": 87, "train_loss": 0.24928154992630414, "val_loss": 0.15886497686180887, "learning_rate": 0.001}, {"epoch": 88, "train_loss": 0.24906658367885043, "val_loss": 0.15837428897996492, "learning_rate": 0.001}, {"epoch": 89, "train_loss": 0.24894628896737647, "val_loss": 0.15976279992845993, "learning_rate": 0.001}, {"epoch": 90, "train_loss": 0.24875361710558158, "val_loss": 0.15790544110762922, "learning_rate": 0.001}, {"epoch": 91, "train_loss": 0.24876114451671805, "val_loss": 0.15863064233260818, "learning_rate": 0.001}, {"epoch": 92, "train_loss": 0.248392353163046, "val_loss": 0.15879830510555942, "learning_rate": 0.001}, {"epoch": 93, "train_loss": 0.2485186197340031, "val_loss": 0.1584750246020812, "learning_rate": 0.001}, {"epoch": 94, "train_loss": 0.2484576696020258, "val_loss": 0.15682796360571175, "learning_rate": 0.001}, {"epoch": 95, "train_loss": 0.24835671800786577, "val_loss": 0.1582510035626496, "learning_rate": 0.001}, {"epoch": 96, "train_loss": 0.248238493300155, "val_loss": 0.157966115052187, "learning_rate": 0.001}, {"epoch": 97, "train_loss": 0.24819543443220046, "val_loss": 0.15755924884277053, "learning_rate": 0.001}, {"epoch": 98, "train_loss": 0.24805999293809047, "val_loss": 0.1578911139240748, "learning_rate": 0.0001}, {"epoch": 99, "train_loss": 0.24371073469329063, "val_loss": 0.15264369075811363, "learning_rate": 0.0001}, {"epoch": 100, "train_loss": 0.24276760597820476, "val_loss": 0.15201256490206416, "learning_rate": 0.0001}, {"epoch": 101, "train_loss": 0.2426636397381268, "val_loss": 0.15167735818820663, "learning_rate": 0.0001}, {"epoch": 102, "train_loss": 0.24223649025420704, "val_loss": 0.15150145375275914, "learning_rate": 0.0001}, {"epoch": 103, "train_loss": 0.24203790419394403, "val_loss": 0.15166795423513726, "learning_rate": 0.0001}, {"epoch": 104, "train_loss": 0.24193367685960687, "val_loss": 0.15132276977919326, "learning_rate": 0.0001}, {"epoch": 105, "train_loss": 0.24171664037972765, "val_loss": 0.15126379324665554, "learning_rate": 0.0001}, {"epoch": 106, "train_loss": 0.24206637989377122, "val_loss": 0.15162455017053628, "learning_rate": 0.0001}, {"epoch": 107, "train_loss": 0.24178273423248545, "val_loss": 0.15125965845735767, "learning_rate": 0.0001}, {"epoch": 108, "train_loss": 0.24165032777335027, "val_loss": 0.15110569871679136, "learning_rate": 0.0001}, {"epoch": 109, "train_loss": 0.24161828223549192, "val_loss": 0.15131595787368243, "learning_rate": 0.0001}, {"epoch": 110, "train_loss": 0.2417310603591792, "val_loss": 0.1512419347521625, "learning_rate": 0.0001}, {"epoch": 111, "train_loss": 0.241698268467508, "val_loss": 0.15126220542418806, "learning_rate": 0.0001}, {"epoch": 112, "train_loss": 0.24153925070677268, "val_loss": 0.1510463615384283, "learning_rate": 0.0001}, {"epoch": 113, "train_loss": 0.2418669448865344, "val_loss": 0.15112877269334432, "learning_rate": 0.0001}]}