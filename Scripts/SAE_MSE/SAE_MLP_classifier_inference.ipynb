{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450aaf57-869e-45df-84c8-c69fdd23c5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/50745734/ipykernel_1996409/2446135461.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('SAE_classifier_best_model.pth', map_location=device)\n",
      "/scratch/local/50745734/ipykernel_1996409/2446135461.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  autoencoder_checkpoint = torch.load('SAE_best_model.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved as CSV to confusion_matrix.csv\n",
      "Confusion matrix saved as PNG to confusion_matrix.png\n",
      "Test evaluation statistics saved to test_evaluation_stats.csv\n",
      "Accuracy on test set: 72.18%\n",
      "Mean inference time per image: 0.001180 seconds\n",
      "Variance of inference time per image: 0.000013 seconds^2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations (same as in training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1, 1]\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image to a vector\n",
    "])\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.KMNIST(root='../data', train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader for test dataset with batch_size=1 to measure time per image\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load the saved classifier model\n",
    "checkpoint = torch.load('SAE_classifier_best_model.pth', map_location=device)\n",
    "\n",
    "# Get model configuration\n",
    "config = checkpoint['config']\n",
    "encoder_output_size = config['encoder_output_size']\n",
    "classifier_hidden_sizes = config['classifier_hidden_sizes']\n",
    "leaky_relu_negative_slope = config['leaky_relu_negative_slope']\n",
    "batch_norm = config['batch_norm']\n",
    "\n",
    "# Rebuild the autoencoder encoder\n",
    "# Load the autoencoder model\n",
    "autoencoder_checkpoint = torch.load('SAE_best_model.pth', map_location=device)\n",
    "\n",
    "# Get the autoencoder config\n",
    "autoencoder_config = autoencoder_checkpoint['config']\n",
    "input_size = autoencoder_config['input_size']\n",
    "layer_sizes = autoencoder_config['layer_sizes']\n",
    "dropout_rates = autoencoder_config['dropout_rates']\n",
    "activation_functions = [nn.LeakyReLU(negative_slope=0.01) for _ in layer_sizes]  # Assuming LeakyReLU\n",
    "\n",
    "# Rebuild the autoencoder (from your SAE_model.py)\n",
    "from SAE_model import StackedAutoencoder\n",
    "\n",
    "autoencoder = StackedAutoencoder(\n",
    "    input_size=input_size,\n",
    "    layer_sizes=layer_sizes,\n",
    "    activation_functions=activation_functions,\n",
    "    dropout_rates=dropout_rates,\n",
    "    weight_init=None  # We don't need to initialize weights, as we'll load them\n",
    ").to(device)\n",
    "\n",
    "# Load the autoencoder state dict\n",
    "autoencoder.load_state_dict(autoencoder_checkpoint['state_dict'])\n",
    "\n",
    "# Build the classifier model\n",
    "class SAEClassifier(nn.Module):\n",
    "    def __init__(self, encoder, encoder_output_size, classifier_hidden_sizes, num_classes, leaky_relu_negative_slope=0.01, batch_norm=True):\n",
    "        super(SAEClassifier, self).__init__()\n",
    "        # Encoder (pre-trained)\n",
    "        self.encoder = encoder  # We will freeze this\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Classifier head\n",
    "        layers = []\n",
    "        prev_size = encoder_output_size  # The output size of the encoder\n",
    "        for idx, hidden_size in enumerate(classifier_hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.LeakyReLU(negative_slope=leaky_relu_negative_slope))\n",
    "            prev_size = hidden_size\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, 10))  # KMNIST has 10 classes\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SAEClassifier(\n",
    "    encoder=autoencoder.encoder,\n",
    "    encoder_output_size=encoder_output_size,\n",
    "    classifier_hidden_sizes=classifier_hidden_sizes,\n",
    "    num_classes=10,  # KMNIST has 10 classes\n",
    "    leaky_relu_negative_slope=leaky_relu_negative_slope,\n",
    "    batch_norm=batch_norm\n",
    ").to(device)\n",
    "\n",
    "# Load the classifier state dict\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model on the test data, recording computation time per image\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "computation_times = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Synchronize CUDA for accurate timing if using GPU\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        outputs = model(inputs)\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "        computation_time = end_time - start_time\n",
    "        computation_times.append(computation_time)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Save confusion matrix as CSV\n",
    "cm_df = pd.DataFrame(cm)\n",
    "cm_csv_filename = 'confusion_matrix.csv'\n",
    "cm_df.to_csv(cm_csv_filename, index=False)\n",
    "print(f\"Confusion matrix saved as CSV to {cm_csv_filename}\")\n",
    "\n",
    "# Save confusion matrix as PNG\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('True Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "cm_png_filename = 'confusion_matrix.png'\n",
    "plt.savefig(cm_png_filename)\n",
    "plt.close()\n",
    "print(f\"Confusion matrix saved as PNG to {cm_png_filename}\")\n",
    "\n",
    "# Compute mean and variance of computation time per image\n",
    "computation_times = np.array(computation_times)\n",
    "mean_time = np.mean(computation_times)\n",
    "variance_time = np.var(computation_times)\n",
    "\n",
    "# Compute accuracy\n",
    "correct = np.sum(np.array(all_preds) == np.array(all_labels))\n",
    "total = len(all_labels)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "# Save computation time statistics and accuracy in a CSV\n",
    "stats = {\n",
    "    'mean_time_per_image': [mean_time],\n",
    "    'variance_time_per_image': [variance_time],\n",
    "    'accuracy': [accuracy]\n",
    "}\n",
    "stats_df = pd.DataFrame(stats)\n",
    "stats_csv_filename = 'test_evaluation_stats.csv'\n",
    "stats_df.to_csv(stats_csv_filename, index=False)\n",
    "print(f\"Test evaluation statistics saved to {stats_csv_filename}\")\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "print(f\"Mean inference time per image: {mean_time:.6f} seconds\")\n",
    "print(f\"Variance of inference time per image: {variance_time:.6f} seconds^2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
